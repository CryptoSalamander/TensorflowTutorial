{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec 예제 구현\n",
    "Word2Vec 모델을 구현해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic\n"
     ]
    }
   ],
   "source": [
    "font_name = matplotlib.font_manager.FontProperties(\n",
    "                        fname=\"/Library/Fonts/NanumGothic.ttf\").get_name()\n",
    "print(font_name)\n",
    "matplotlib.rc('font', family=\"NanumGothic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"나 고양이 좋다\",\n",
    "             \"나 강아지 좋다\",\n",
    "             \"나 동물 좋다\",\n",
    "             \"강아지 고양이 동물\",\n",
    "             \"여자친구 고양이 강아지 좋다\",\n",
    "             \"고양이 생선 우유 좋다\",\n",
    "             \"강아지 생선 싫다 우유 좋다\",\n",
    "             \"강아지 고양이 눈 좋다\",\n",
    "             \"나 여자친구 좋다\",\n",
    "             \"여자친구 나 싫다\",\n",
    "             \"여자친구 나 영화 책 음악 좋다\",\n",
    "             \"나 게임 만화 애니 좋다\",\n",
    "             \"고양이 강아지 싫다\",\n",
    "             \"강아지 고양이 좋다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence = \" \".join(sentences).split()\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장을 전부 합친 후에 공백으로 단어들을 나누고 이를 바탕으로 리스트를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {w: i for i, w in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열 자체보다는 숫자로 분석하는 것이 훨씬 용이하므로, 리스트에서 문자들의 인덱스를 뽑아서 사용하고 위해 인덱스 배열을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams = []\n",
    "\n",
    "for i in range(1, len(word_sequence) - 1):\n",
    "    target = word_dict[word_sequence[i]]\n",
    "    context = [word_dict[word_sequence[i-1]], word_dict[word_sequence[i+1]]]\n",
    "    \n",
    "    for w in context:\n",
    "        skip_grams.append([target,w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윈도우 사이즈를 1로 하는 Skip-gram 모델을 만든다.  \n",
    "스킵그램을 만든 후, 저장은 단어의 index를 통해 저장한다.\n",
    "# Skip-Gram Model 이란?\n",
    "만약 다음과 같은 문장이 있다고 가정하자.  \n",
    "\n",
    "> _**the quick brown fox jumped over the lazy dog.**_  \n",
    "\n",
    "여기서는 간단하게 Context를 현재(목표) 단어의 왼쪽과 오른쪽에 있는 단어들의 윈도우로 정의한다.  \n",
    "윈도우 사이즈를 1로 하면 (context, target) 쌍으로 구성된 다음과 같은 데이터셋을 얻을 수 있다.  \n",
    "\n",
    ">\\\\(([the, brown], quick), ([quick, fox], brown), ([brown,jumped],fox), ...\\\\)  \n",
    "\n",
    "우리가 만약 'quick'으로부터 Context 'the' 와 'brown' 을 예측해야 한다면, 다음의 데이터셋이 활용된다.  \n",
    "\n",
    ">\\\\((quick, the), (quick, brown), (brown, quick), (brown, fox), ...\\\\)  \n",
    "\n",
    "\n",
    "### Ex) Windows가 2일 경우\n",
    "![Image](https://i.imgur.com/8zNRwsn.png)\n",
    "\n",
    "목적 함수는 성능상의 이유로 보통 Stochastic Gradient Descent Descent(SGD) 알고리즘을 사용해서   \n",
    "하나 또는 minibatch 라고 부르는 일정 개수의 데이터(배치)로 묶어서 최적화한다.   \n",
    "일반적으로 데이터 개수는 16 ~ 512 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(data,size):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
    "    \n",
    "    for i in random_index:\n",
    "        random_inputs.append(data[i][0])\n",
    "        random_labels.append([data[i][1]])\n",
    "        \n",
    "    return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Option Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 300\n",
    "learning_rate = 0.1\n",
    "batch_size = 20\n",
    "embedding_size = 2\n",
    "num_sampled = 15\n",
    "voc_size = len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training_epoch : 학습을 반복할 횟수\n",
    "- learning_rate = 학습률(Gradient Descent의 정도)\n",
    "- batch_size = 한번에 학습할 데이터의 크기\n",
    "- embedding_size = 단어 벡터를 구성할 Dimension 크기\n",
    "- num_sampled = word2vec 모델을 학습하는 nce_loss 함수에서 사용하는 샘플링의 크기  \n",
    "(batch_size 보다 작아야 한다.)\n",
    "- voc_size = 총 단어의 갯수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size , 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.nce_loss를 사용하기 위해서 [batch_size, 1] 꼴로 구성을 한다.\n",
    "# NCE(Noise-Contrastive Estimation)이란?\n",
    "CBOW와 Skip-Gram 모델에서 사용하는 Cost 알고리즘이다. 전체 데이터셋에 대해 SoftMax 함수를 적용하는 것이 아니라 샘플링으류 추출한 일부에 대해서만 적용하는 방법을 말한다. K개의 대비되는(Contrastive) 단어들을 noise distribution에서 구해서 Monte Carlo 평균을 구하는 것이 기본 알고리즘이다.  \n",
    "일반적으로 단어 갯수가 많을 때 사용하고, NCE를 사용하면 문제를 실제 데이터에서 얻은 샘플과 인공적으로 만든 잡음 분포에서 얻은 샘플을 구별하는 이진 분류 문제로 바꿀 수 있게 된다.\n",
    "모든 단어에 대해서 Softmax을 계산하고 Normalization을 하기엔 너무 오래걸리므로 Negative Sampling, Hierachical Softmax등의 방법을 사용한다.\n",
    "## Negative Sampling ( tf.nn.nce_loss )\n",
    "Negative Sampling에서 사용하는 목적 함수는 결과값이 최대화될 수 있는 형태로 구성된다. 현재(목표, target, positive) 단어에는 높은 확률을 부여하고, 나머지 단어(negative, noise)에는 낮은 확률을 부여해서 가장 큰 값을 만들 수 있는 공식을 사용한다. 특히 Cost에서 전체 단어 V를 계산하는 것이 아니라 선택한 k개의 noise 단어들만 계산하면 되기 때문에 효율적이다. 텐서플로우에서는 tf.nn.nce_loss()로 구현되어 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec 모델의 결과 값인 임베딩 벡터를 저장할 변수를 선언하고, 총 단어 개수와 임베딩 개수를 크기로 하는 두 개의 차원으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원에서 학습할 입력값에 대한 행들을 뽑아온다.  \n",
    "embedd     &nbsp;&nbsp;inputs  &nbsp;&nbsp;  selected  \n",
    "    [1, 2, 3]  -> [2, 3] -> [2, 3, 4]  \n",
    "    [2, 3, 4]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  [3, 4, 5]  \n",
    "    [3, 4, 5]  \n",
    "    [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientDescent가 아닌 AdamOptimizer를 사용한다.  \n",
    "별도의 작업은 필요없고, 그냥 함수이름만 다르게 쓰면 된다.  \n",
    "Adam은 현존하는 알고리즘 중에서 가장 강력한 성능을 보여주는 최적화 알고리즘이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step  10 :  5.203868\n",
      "loss at step  20 :  3.5246475\n",
      "loss at step  30 :  3.7621956\n",
      "loss at step  40 :  3.1559167\n",
      "loss at step  50 :  3.433635\n",
      "loss at step  60 :  3.4259632\n",
      "loss at step  70 :  3.4869142\n",
      "loss at step  80 :  3.2576058\n",
      "loss at step  90 :  3.0651166\n",
      "loss at step  100 :  3.124257\n",
      "loss at step  110 :  3.3450248\n",
      "loss at step  120 :  3.3538356\n",
      "loss at step  130 :  3.5285785\n",
      "loss at step  140 :  3.3762956\n",
      "loss at step  150 :  3.260347\n",
      "loss at step  160 :  3.2661934\n",
      "loss at step  170 :  3.118836\n",
      "loss at step  180 :  3.2403705\n",
      "loss at step  190 :  2.8177452\n",
      "loss at step  200 :  2.9476116\n",
      "loss at step  210 :  3.3562312\n",
      "loss at step  220 :  3.3118114\n",
      "loss at step  230 :  2.8114314\n",
      "loss at step  240 :  3.170344\n",
      "loss at step  250 :  3.353152\n",
      "loss at step  260 :  3.0314388\n",
      "loss at step  270 :  3.4905643\n",
      "loss at step  280 :  3.1049454\n",
      "loss at step  290 :  3.193821\n",
      "loss at step  300 :  3.3837783\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, training_epoch + 1):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                                          feed_dict={inputs: batch_inputs,\n",
    "                                                            labels: batch_labels})\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss at step \", step, \": \", loss_val)\n",
    "    \n",
    "    trained_embeddings = embeddings.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 된 Word2Vec 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['NanumGothic'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, label in enumerate(word_list):\n",
    "    x, y = trained_embeddings[i]\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label, xy=(x,y), xytext=(5,2),\n",
    "                         textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
