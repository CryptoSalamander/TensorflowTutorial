{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\",\"all\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "train_data0 = pd.read_csv(\"all/train.csv\")\n",
    "print(train_data0.shape)\n",
    "train_data = np.array(train_data0.iloc[:, 1:785])\n",
    "train_label = np.array(train_data0.iloc[:,0])\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_label = to_categorical(train_label, num_classes=10)\n",
    "print(train_label[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_data0 = pd.read_csv(\"all/test.csv\")\n",
    "print(test_data0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(test_data0)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 4 0 0 7 3 5 3]\n",
      "is equivalent to :\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_data0.iloc[:,0])[:10])\n",
    "print('is equivalent to :')\n",
    "print(train_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   5  60 136 136 147 254 255\n",
      " 199 111  18   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  25 152 253 253 253 253 253 253 253 253 253 124   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 135 225 244 253 202 200\n",
      " 181 164 216 253 253 211 151   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  30 149  78   3   0   0   0  20 134 253 253 224   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  28 206 253 253 224   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  78 253 253 253\n",
      " 224   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   5  99 234 253 253 224   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  14 142 220 219 236\n",
      " 253 253 240 121   7   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  24 253 253 253 253 235 233 253 253 185  53   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8 150 194\n",
      " 194 194  53  40  97 253 253 170   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 122 253 253 170\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  55 237 253 253 170   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 130 253 253\n",
      " 253 170   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   4  12 120 193 253 253 214  28   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   7 153 253 253 253\n",
      " 253 212  30   0   0   0   0   0   0   0   0   0   0   0   0   0  33 136\n",
      "  70   6   0  27  67 186 253 253 253 253 234  31   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  26 231 253 253 191 183 223 253 253 253 253\n",
      " 172 216 112   0   0   0   0   0   0   0   0   0   0   0   0   0   0  36\n",
      " 215 253 253 253 253 253 253 253 253 253  47  25   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   5  87 223 253 253 253 244 152 223\n",
      " 223 109   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  67  50 176 148  78  16   0  12  12   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data[9])\n",
    "pixels = train_data[9].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = train_data[7].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADJFJREFUeJzt3V+IHfUZxvHnMeqFqxea6BJsrFbEULxIdSOFxmBp/VMRktyIAUtKJVtEoYVeVK3QQK2E0iq9KiQYjJJqC240F9LGBukilJIoqX92U7USTULMNlpQyYXVvL3YEVbdM3M8Z86Z2bzfDyx7zvxmzryOefY3c+bPzxEhAPmc1nQBAJpB+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJHX6MFdmm8sJgQGLCHczX189v+0bbf/L9hu27+7nswAMl3u9tt/2IkmvSbpO0mFJeyWtj4ipkmXo+YEBG0bPf7WkNyLizYj4SNITktb08XkAhqif8F8o6dCc94eLaZ9he9z2Ptv7+lgXgJoN/Au/iNgiaYvEbj/QJv30/EckLZvz/ivFNAALQD/h3yvpMtuX2D5T0q2SdtVTFoBB63m3PyI+tn2XpL9IWiRpW0S8WltlAAaq51N9Pa2MY35g4IZykQ+AhYvwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpHoeoluSbB+U9IGkTyR9HBFjdRQFYPD6Cn/h2xFxvIbPATBE7PYDSfUb/pC02/YLtsfrKAjAcPS7278qIo7YvkDSs7YPRMTk3BmKPwr8YQBaxhFRzwfZmyR9GBG/KZmnnpUB6Cgi3M18Pe/22x6xfc6nryVdL+mVXj8PwHD1s9s/Kmmn7U8/5w8R8edaqgIwcLXt9ne1Mnb7gYEb+G4/gIWN8ANJEX4gKcIPJEX4gaQIP5BUHXf1pbBu3bqObTfccEPpsjt37ixtP368v5si33777Y5tixcvLl12ZGSkr3X3Y/Xq1aXta9euLW2fnp4ubX/ggQc6tpVtsyzo+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKW7p7dI999zTse3+++8vXbZqGxfPROh5+UOHDnVsW7JkSemyZ511Vl/r7qf2fv+733333dL2lStXdmw7lc/zc0svgFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU9/N36bTTOv+dvOOOO0qXnZycLG2vuq99IVu1alXHtttuu62vz96xY0dp+6l8Lr8O9PxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFTleX7b2yTdLGkmIq4opp0n6Y+SLpZ0UNItEfHfwZXZvLJnyG/durV02QMHDvTVvpCVjXdQdb/+1NRUaXvZc/lRrZue/xFJN35u2t2S9kTEZZL2FO8BLCCV4Y+ISUnvfW7yGknbi9fbJZUPrQKgdXo95h+NiKPF63ckjdZUD4Ah6fva/oiIsmfz2R6XNN7vegDUq9ee/5jtpZJU/J7pNGNEbImIsYgY63FdAAag1/DvkrSheL1B0tP1lANgWCrDb/txSX+XdLntw7Zvl7RZ0nW2X5f03eI9gAWk8pg/ItZ3aPpOzbUsWMuXL2+6hMaMjIyUtl900UUd26qe2795c3mfcvz48dJ2lOMKPyApwg8kRfiBpAg/kBThB5Ii/EBSPLq7UHW6rqy96pbeU1nVdrv88ss7tk1MTJQuu3Pnzp5qQnfo+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKc7zd4nbR+f32GOPlbaX3ba7e/fu0mVPnDjRU03oDj0/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFef5C1TDZK1euHFIlC0vZ/fpS9TDcaA49P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kVXme3/Y2STdLmomIK4ppmyRtlPSfYrZ7I+KZQRXZBlnv51+9enVpe9Uw22UmJyd7Xhb966bnf0TSjfNMfygiVhQ/p3TwgVNRZfgjYlLSe0OoBcAQ9XPMf5ftl2xvs31ubRUBGIpew/97SZdKWiHpqKTfdprR9rjtfbb39bguAAPQU/gj4lhEfBIRJyVtlXR1ybxbImIsIsZ6LRJA/XoKv+2lc96uk/RKPeUAGJZuTvU9LulaSUtsH5b0C0nX2l4hKSQdlPSjAdYIYAAqwx8R6+eZ/PAAakELLV++vLS96n79iYmJjm1Vz1DAYHGFH5AU4QeSIvxAUoQfSIrwA0kRfiApHt2NUtdcc01pe9UtvU899VSd5aBG9PxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTn+VGq31t6p6en6ywHNaLnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkOM+f3FVXXVXafuWVV5a29zNEN5pFzw8kRfiBpAg/kBThB5Ii/EBShB9IivADSVWG3/Yy28/ZnrL9qu0fF9PPs/2s7deL3+cOvlwMW0T09YP26qbn/1jSTyPi65K+KelO21+XdLekPRFxmaQ9xXsAC0Rl+CPiaES8WLz+QNK0pAslrZG0vZhtu6S1gyoSQP2+1DG/7YslfUPSPySNRsTRoukdSaO1VgZgoLq+tt/22ZKelPSTiHh/7jXdERG25z3Asz0uabzfQgHUq6ue3/YZmg3+joiYKCYfs720aF8qaWa+ZSNiS0SMRcRYHQUDqEc33/Zb0sOSpiPiwTlNuyRtKF5vkPR0/eUBGJRudvu/Jen7kl62vb+Ydq+kzZL+ZPt2SW9JumUwJaJJVbfsckvvwlUZ/oh4XlKn/8PfqbccAMPCFX5AUoQfSIrwA0kRfiApwg8kRfiBpHh0N0pV3ZZ74MCBvtrRHHp+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8/zJbdy4sbS96n79++67r7T9xIkTX7omDAc9P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k5WEOo9xpSC8059ixY6XtixcvLm0//XQuFWmbiOhqMAV6fiApwg8kRfiBpAg/kBThB5Ii/EBShB9IqvIkre1lkh6VNCopJG2JiN/Z3iRpo6T/FLPeGxHPDKpQ9Ob8888vbb/gggtK20+ePFlnOWiRbq7Q+FjSTyPiRdvnSHrB9rNF20MR8ZvBlQdgUCrDHxFHJR0tXn9ge1rShYMuDMBgfaljftsXS/qGpH8Uk+6y/ZLtbbbP7bDMuO19tvf1VSmAWnV9bb/tsyX9TdKvImLC9qik45r9HuCXkpZGxA8rPoNr+4es6ph/ZmamtL3qmH/RokVfuiYMVq3X9ts+Q9KTknZExESxgmMR8UlEnJS0VdLVvRYLYPgqw+/Zx7c+LGk6Ih6cM33pnNnWSXql/vIADEo33/Z/S9L3Jb1se38x7V5J622v0Oxu/0FJPxpIhehL1WFd1W791NRUneWgRbr5tv95SfMdQ3BOH1jAuMIPSIrwA0kRfiApwg8kRfiBpAg/kBSP7gZOMTy6G0Apwg8kRfiBpAg/kBThB5Ii/EBShB9IatjjKx+X9Nac90uKaW3U1traWpdEbb2qs7avdjvjUC/y+cLK7X0RMdZYASXaWltb65KorVdN1cZuP5AU4QeSajr8Wxpef5m21tbWuiRq61UjtTV6zA+gOU33/AAa0kj4bd9o+1+237B9dxM1dGL7oO2Xbe9veoixYhi0GduvzJl2nu1nbb9e/J53mLSGattk+0ix7fbbvqmh2pbZfs72lO1Xbf+4mN7otiupq5HtNvTdftuLJL0m6TpJhyXtlbQ+IlrxgHjbByWNRUTj54Rtr5b0oaRHI+KKYtqvJb0XEZuLP5znRsTPWlLbJkkfNj1yczGgzNK5I0tLWivpB2pw25XUdYsa2G5N9PxXS3ojIt6MiI8kPSFpTQN1tF5ETEp673OT10jaXrzertl/PEPXobZWiIijEfFi8foDSZ+OLN3otiupqxFNhP9CSYfmvD+sdg35HZJ2237B9njTxcxjtBg2XZLekTTaZDHzqBy5eZg+N7J0a7ZdLyNe140v/L5oVURcKel7ku4sdm9bKWaP2dp0uub3ki6VtELSUUm/bbKYYmTpJyX9JCLen9vW5Labp65GtlsT4T8iadmc918pprVCRBwpfs9I2qn2jT587NNBUovf5WNsD1GbRm6eb2RptWDbtWnE6ybCv1fSZbYvsX2mpFsl7Wqgji+wPVJ8ESPbI5KuV/tGH94laUPxeoOkpxus5TPaMnJzp5Gl1fC2a92I1xEx9B9JN2n2G/9/S/p5EzV0qOtrkv5Z/LzadG2SHtfsbuD/NPvdyO2SFkvaI+l1SX+VdF6LantM0suSXtJs0JY2VNsqze7SvyRpf/FzU9PbrqSuRrYbV/gBSfGFH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpP4PoZQx6Sx9WhcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = train_data[6].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_55:0' shape=() dtype=int32_ref>\n",
      "<tf.Variable 'Variable_56:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00005\n",
    "epoch = 40\n",
    "batch_size = 20\n",
    "\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "def conv2d(name, x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.elu(x, name=name)\n",
    "\n",
    "def maxpool2d(name, x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,k,k,1], padding = 'SAME')\n",
    "\n",
    "weights = {\n",
    "    'W1' : tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1)),\n",
    "    'W2' : tf.Variable(tf.truncated_normal([5,5,32,64], stddev=0.1)),\n",
    "    'W4' : tf.Variable(tf.truncated_normal([64*7*7,784],stddev=0.1)),\n",
    "    'Wo' : tf.Variable(tf.truncated_normal([784,n_classes], stddev=0.1))\n",
    "}\n",
    "a = tf.Variable(1)\n",
    "print(a)\n",
    "print(tf.Variable(tf.truncated_normal([5,5,1,32],stddev=0.1)))\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([32],stddev=0.1)),\n",
    "    'b2' : tf.Variable(tf.random_normal([64], stddev=0.1)),\n",
    "    'b4' : tf.Variable(tf.random_normal([784], stddev=0.1)),\n",
    "    'bo' : tf.Variable(tf.random_normal([n_classes], stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, weights , biases):\n",
    "    x = tf.reshape(X, [-1,28,28,1]) #padding\n",
    "    x = x/255 #normalization\n",
    "    \n",
    "    conv1 = tf.nn.elu(conv2d('conv1', x, weights['W1'], biases['b1'])) \n",
    "    pool1 = maxpool2d('pool1', conv1, k=2)\n",
    "    \n",
    "    conv2 = tf.nn.elu(conv2d('conv2',pool1,weights['W2'],biases['b2']))\n",
    "    pool2 = maxpool2d('pool2',conv2,k=2)\n",
    "    \n",
    "    fc = tf.reshape(pool2, [-1, weights['W4'].get_shape().as_list()[0]])\n",
    "    fc = tf.add(tf.matmul(fc,weights['W4']), biases['b4'])\n",
    "    fc = tf.nn.elu(fc)\n",
    "    \n",
    "    a = tf.add(tf.matmul(fc, weights['Wo']), biases['bo'])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "label = tf.argmax(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(label, tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100, Minibatch Loss = 2.22756290436, Training accuracy = 0.20000000298\n",
      "Iter 200, Minibatch Loss = 1.47197127342, Training accuracy = 0.600000023842\n",
      "Iter 300, Minibatch Loss = 1.22464263439, Training accuracy = 0.600000023842\n",
      "Iter 400, Minibatch Loss = 1.00303459167, Training accuracy = 0.699999988079\n",
      "Iter 500, Minibatch Loss = 0.91278553009, Training accuracy = 0.600000023842\n",
      "Iter 600, Minibatch Loss = 0.953575491905, Training accuracy = 0.600000023842\n",
      "Iter 700, Minibatch Loss = 0.731966853142, Training accuracy = 0.699999988079\n",
      "Iter 800, Minibatch Loss = 0.613800227642, Training accuracy = 0.800000011921\n",
      "Iter 900, Minibatch Loss = 0.385223686695, Training accuracy = 0.899999976158\n",
      "Iter 1000, Minibatch Loss = 0.489326417446, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.983053028584, Training accuracy = 0.699999988079\n",
      "Iter 1200, Minibatch Loss = 0.922894477844, Training accuracy = 0.699999988079\n",
      "Iter 1300, Minibatch Loss = 1.16084730625, Training accuracy = 0.600000023842\n",
      "Iter 1400, Minibatch Loss = 0.434795230627, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.202212169766, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.198506683111, Training accuracy = 0.899999976158\n",
      "Iter 1700, Minibatch Loss = 0.0721758231521, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.313405930996, Training accuracy = 0.800000011921\n",
      "Iter 1900, Minibatch Loss = 0.137322947383, Training accuracy = 1.0\n",
      "Iter 2000, Minibatch Loss = 0.202626615763, Training accuracy = 1.0\n",
      "Iter 2100, Minibatch Loss = 0.18504627049, Training accuracy = 0.899999976158\n",
      "Iter 2200, Minibatch Loss = 0.138153269887, Training accuracy = 0.899999976158\n",
      "Iter 2300, Minibatch Loss = 0.289972633123, Training accuracy = 0.899999976158\n",
      "Iter 2400, Minibatch Loss = 0.153898864985, Training accuracy = 0.899999976158\n",
      "Iter 2500, Minibatch Loss = 0.254063427448, Training accuracy = 0.899999976158\n",
      "Iter 2600, Minibatch Loss = 0.0591100826859, Training accuracy = 1.0\n",
      "Iter 2700, Minibatch Loss = 0.583254396915, Training accuracy = 0.899999976158\n",
      "Iter 2800, Minibatch Loss = 0.564308822155, Training accuracy = 0.800000011921\n",
      "Iter 2900, Minibatch Loss = 0.212425589561, Training accuracy = 0.899999976158\n",
      "Iter 3000, Minibatch Loss = 0.452349483967, Training accuracy = 0.800000011921\n",
      "Iter 3100, Minibatch Loss = 0.527801215649, Training accuracy = 0.800000011921\n",
      "Iter 3200, Minibatch Loss = 0.41130656004, Training accuracy = 0.899999976158\n",
      "Iter 3300, Minibatch Loss = 0.364243745804, Training accuracy = 0.800000011921\n",
      "Iter 3400, Minibatch Loss = 0.094645678997, Training accuracy = 1.0\n",
      "Iter 3500, Minibatch Loss = 0.348956227303, Training accuracy = 0.899999976158\n",
      "Iter 3600, Minibatch Loss = 0.104260072112, Training accuracy = 1.0\n",
      "Iter 3700, Minibatch Loss = 0.0911364778876, Training accuracy = 1.0\n",
      "Iter 3800, Minibatch Loss = 0.204686835408, Training accuracy = 0.800000011921\n",
      "Iter 3900, Minibatch Loss = 0.480857431889, Training accuracy = 0.899999976158\n",
      "Iter 4000, Minibatch Loss = 0.186751514673, Training accuracy = 0.899999976158\n",
      "Iter 4100, Minibatch Loss = 0.0317121073604, Training accuracy = 1.0\n",
      "Iter 4200, Minibatch Loss = 0.0238961111754, Training accuracy = 1.0\n",
      "Iter 100, Minibatch Loss = 0.0462845154107, Training accuracy = 1.0\n",
      "Iter 200, Minibatch Loss = 0.0356685332954, Training accuracy = 1.0\n",
      "Iter 300, Minibatch Loss = 0.0734488293529, Training accuracy = 1.0\n",
      "Iter 400, Minibatch Loss = 0.360227525234, Training accuracy = 0.899999976158\n",
      "Iter 500, Minibatch Loss = 0.0298096053302, Training accuracy = 1.0\n",
      "Iter 600, Minibatch Loss = 0.587853431702, Training accuracy = 0.800000011921\n",
      "Iter 700, Minibatch Loss = 0.0569052584469, Training accuracy = 1.0\n",
      "Iter 800, Minibatch Loss = 0.38946056366, Training accuracy = 0.800000011921\n",
      "Iter 900, Minibatch Loss = 0.0715129822493, Training accuracy = 1.0\n",
      "Iter 1000, Minibatch Loss = 0.260687083006, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.432400166988, Training accuracy = 0.800000011921\n",
      "Iter 1200, Minibatch Loss = 0.42374920845, Training accuracy = 0.800000011921\n",
      "Iter 1300, Minibatch Loss = 0.573134720325, Training accuracy = 0.800000011921\n",
      "Iter 1400, Minibatch Loss = 0.330747753382, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.0424069948494, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.0330548658967, Training accuracy = 1.0\n",
      "Iter 1700, Minibatch Loss = 0.0164450276643, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.0676181167364, Training accuracy = 1.0\n",
      "Iter 1900, Minibatch Loss = 0.073950663209, Training accuracy = 1.0\n",
      "Iter 2000, Minibatch Loss = 0.0896474793553, Training accuracy = 1.0\n",
      "Iter 2100, Minibatch Loss = 0.0450911782682, Training accuracy = 1.0\n",
      "Iter 2200, Minibatch Loss = 0.142813414335, Training accuracy = 0.899999976158\n",
      "Iter 2300, Minibatch Loss = 0.0789743959904, Training accuracy = 1.0\n",
      "Iter 2400, Minibatch Loss = 0.0666138008237, Training accuracy = 1.0\n",
      "Iter 2500, Minibatch Loss = 0.140419214964, Training accuracy = 0.899999976158\n",
      "Iter 2600, Minibatch Loss = 0.0263939611614, Training accuracy = 1.0\n",
      "Iter 2700, Minibatch Loss = 0.277970343828, Training accuracy = 0.899999976158\n",
      "Iter 2800, Minibatch Loss = 0.312103480101, Training accuracy = 0.800000011921\n",
      "Iter 2900, Minibatch Loss = 0.0335111394525, Training accuracy = 1.0\n",
      "Iter 3000, Minibatch Loss = 0.338539481163, Training accuracy = 0.800000011921\n",
      "Iter 3100, Minibatch Loss = 0.281431466341, Training accuracy = 0.899999976158\n",
      "Iter 3200, Minibatch Loss = 0.230712562799, Training accuracy = 0.899999976158\n",
      "Iter 3300, Minibatch Loss = 0.18238158524, Training accuracy = 0.899999976158\n",
      "Iter 3400, Minibatch Loss = 0.0683171376586, Training accuracy = 1.0\n",
      "Iter 3500, Minibatch Loss = 0.245123833418, Training accuracy = 0.899999976158\n",
      "Iter 3600, Minibatch Loss = 0.0438845977187, Training accuracy = 1.0\n",
      "Iter 3700, Minibatch Loss = 0.0198806431144, Training accuracy = 1.0\n",
      "Iter 3800, Minibatch Loss = 0.172484666109, Training accuracy = 0.899999976158\n",
      "Iter 3900, Minibatch Loss = 0.1891733706, Training accuracy = 0.899999976158\n",
      "Iter 4000, Minibatch Loss = 0.154445201159, Training accuracy = 0.899999976158\n",
      "Iter 4100, Minibatch Loss = 0.00992846116424, Training accuracy = 1.0\n",
      "Iter 4200, Minibatch Loss = 0.00921308621764, Training accuracy = 1.0\n",
      "Iter 100, Minibatch Loss = 0.0150951296091, Training accuracy = 1.0\n",
      "Iter 200, Minibatch Loss = 0.0309128761292, Training accuracy = 1.0\n",
      "Iter 300, Minibatch Loss = 0.0341574922204, Training accuracy = 1.0\n",
      "Iter 400, Minibatch Loss = 0.426418125629, Training accuracy = 0.899999976158\n",
      "Iter 500, Minibatch Loss = 0.0102898720652, Training accuracy = 1.0\n",
      "Iter 600, Minibatch Loss = 0.399193614721, Training accuracy = 0.800000011921\n",
      "Iter 700, Minibatch Loss = 0.0125727923587, Training accuracy = 1.0\n",
      "Iter 800, Minibatch Loss = 0.327455431223, Training accuracy = 0.899999976158\n",
      "Iter 900, Minibatch Loss = 0.0387437865138, Training accuracy = 1.0\n",
      "Iter 1000, Minibatch Loss = 0.300555408001, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.205687969923, Training accuracy = 1.0\n",
      "Iter 1200, Minibatch Loss = 0.191637441516, Training accuracy = 0.899999976158\n",
      "Iter 1300, Minibatch Loss = 0.360309481621, Training accuracy = 0.899999976158\n",
      "Iter 1400, Minibatch Loss = 0.302065759897, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.0246619377285, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.0132137630135, Training accuracy = 1.0\n",
      "Iter 1700, Minibatch Loss = 0.00916787609458, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.0385158844292, Training accuracy = 1.0\n",
      "Iter 1900, Minibatch Loss = 0.0472026839852, Training accuracy = 1.0\n",
      "Iter 2000, Minibatch Loss = 0.055519990623, Training accuracy = 1.0\n",
      "Iter 2100, Minibatch Loss = 0.0177473481745, Training accuracy = 1.0\n",
      "Iter 2200, Minibatch Loss = 0.135211929679, Training accuracy = 0.899999976158\n",
      "Iter 2300, Minibatch Loss = 0.0204067323357, Training accuracy = 1.0\n",
      "Iter 2400, Minibatch Loss = 0.0328886210918, Training accuracy = 1.0\n",
      "Iter 2500, Minibatch Loss = 0.0745586827397, Training accuracy = 1.0\n",
      "Iter 2600, Minibatch Loss = 0.0196073055267, Training accuracy = 1.0\n",
      "Iter 2700, Minibatch Loss = 0.131594151258, Training accuracy = 0.899999976158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2800, Minibatch Loss = 0.181100219488, Training accuracy = 0.800000011921\n",
      "Iter 2900, Minibatch Loss = 0.0112752299756, Training accuracy = 1.0\n",
      "Iter 3000, Minibatch Loss = 0.235515743494, Training accuracy = 0.899999976158\n",
      "Iter 3100, Minibatch Loss = 0.194180324674, Training accuracy = 0.899999976158\n",
      "Iter 3200, Minibatch Loss = 0.151329085231, Training accuracy = 1.0\n",
      "Iter 3300, Minibatch Loss = 0.112877011299, Training accuracy = 0.899999976158\n",
      "Iter 3400, Minibatch Loss = 0.0466692820191, Training accuracy = 1.0\n",
      "Iter 3500, Minibatch Loss = 0.169158726931, Training accuracy = 0.899999976158\n",
      "Iter 3600, Minibatch Loss = 0.028292587027, Training accuracy = 1.0\n",
      "Iter 3700, Minibatch Loss = 0.00818279385567, Training accuracy = 1.0\n",
      "Iter 3800, Minibatch Loss = 0.12999971211, Training accuracy = 0.899999976158\n",
      "Iter 3900, Minibatch Loss = 0.0671806558967, Training accuracy = 1.0\n",
      "Iter 4000, Minibatch Loss = 0.139138251543, Training accuracy = 0.899999976158\n",
      "Iter 4100, Minibatch Loss = 0.00494813267142, Training accuracy = 1.0\n",
      "Iter 4200, Minibatch Loss = 0.00540150329471, Training accuracy = 1.0\n",
      "Iter 100, Minibatch Loss = 0.00695225223899, Training accuracy = 1.0\n",
      "Iter 200, Minibatch Loss = 0.0242357794195, Training accuracy = 1.0\n",
      "Iter 300, Minibatch Loss = 0.0181031003594, Training accuracy = 1.0\n",
      "Iter 400, Minibatch Loss = 0.462922275066, Training accuracy = 0.899999976158\n",
      "Iter 500, Minibatch Loss = 0.00548626994714, Training accuracy = 1.0\n",
      "Iter 600, Minibatch Loss = 0.258522868156, Training accuracy = 0.800000011921\n",
      "Iter 700, Minibatch Loss = 0.00781861878932, Training accuracy = 1.0\n",
      "Iter 800, Minibatch Loss = 0.285706043243, Training accuracy = 0.899999976158\n",
      "Iter 900, Minibatch Loss = 0.0247712992132, Training accuracy = 1.0\n",
      "Iter 1000, Minibatch Loss = 0.302930086851, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.102409243584, Training accuracy = 1.0\n",
      "Iter 1200, Minibatch Loss = 0.0914848968387, Training accuracy = 1.0\n",
      "Iter 1300, Minibatch Loss = 0.255138009787, Training accuracy = 0.899999976158\n",
      "Iter 1400, Minibatch Loss = 0.25383874774, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.0210459586233, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.00916589982808, Training accuracy = 1.0\n",
      "Iter 1700, Minibatch Loss = 0.00545159820467, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.0217287894338, Training accuracy = 1.0\n",
      "Iter 1900, Minibatch Loss = 0.0326991081238, Training accuracy = 1.0\n",
      "Iter 2000, Minibatch Loss = 0.0325795598328, Training accuracy = 1.0\n",
      "Iter 2100, Minibatch Loss = 0.00945722777396, Training accuracy = 1.0\n",
      "Iter 2200, Minibatch Loss = 0.126912325621, Training accuracy = 0.899999976158\n",
      "Iter 2300, Minibatch Loss = 0.0100268088281, Training accuracy = 1.0\n",
      "Iter 2400, Minibatch Loss = 0.019189555198, Training accuracy = 1.0\n",
      "Iter 2500, Minibatch Loss = 0.0424954630435, Training accuracy = 1.0\n",
      "Iter 2600, Minibatch Loss = 0.0141608864069, Training accuracy = 1.0\n",
      "Iter 2700, Minibatch Loss = 0.0736273750663, Training accuracy = 1.0\n",
      "Iter 2800, Minibatch Loss = 0.120427109301, Training accuracy = 1.0\n",
      "Iter 2900, Minibatch Loss = 0.00506906816736, Training accuracy = 1.0\n",
      "Iter 3000, Minibatch Loss = 0.172499760985, Training accuracy = 0.899999976158\n",
      "Iter 3100, Minibatch Loss = 0.148872047663, Training accuracy = 0.899999976158\n",
      "Iter 3200, Minibatch Loss = 0.111516691744, Training accuracy = 1.0\n",
      "Iter 3300, Minibatch Loss = 0.0828720554709, Training accuracy = 1.0\n",
      "Iter 3400, Minibatch Loss = 0.0274706277996, Training accuracy = 1.0\n",
      "Iter 3500, Minibatch Loss = 0.108131065965, Training accuracy = 0.899999976158\n",
      "Iter 3600, Minibatch Loss = 0.0240390561521, Training accuracy = 1.0\n",
      "Iter 3700, Minibatch Loss = 0.00523171108216, Training accuracy = 1.0\n",
      "Iter 3800, Minibatch Loss = 0.0883642882109, Training accuracy = 0.899999976158\n",
      "Iter 3900, Minibatch Loss = 0.0288253072649, Training accuracy = 1.0\n",
      "Iter 4000, Minibatch Loss = 0.118715263903, Training accuracy = 1.0\n",
      "Iter 4100, Minibatch Loss = 0.00341177964583, Training accuracy = 1.0\n",
      "Iter 4200, Minibatch Loss = 0.00362615589984, Training accuracy = 1.0\n",
      "Iter 100, Minibatch Loss = 0.00385864963755, Training accuracy = 1.0\n",
      "Iter 200, Minibatch Loss = 0.0173409357667, Training accuracy = 1.0\n",
      "Iter 300, Minibatch Loss = 0.0105862794444, Training accuracy = 1.0\n",
      "Iter 400, Minibatch Loss = 0.478150546551, Training accuracy = 0.899999976158\n",
      "Iter 500, Minibatch Loss = 0.00340069038793, Training accuracy = 1.0\n",
      "Iter 600, Minibatch Loss = 0.164206489921, Training accuracy = 1.0\n",
      "Iter 700, Minibatch Loss = 0.00708940625191, Training accuracy = 1.0\n",
      "Iter 800, Minibatch Loss = 0.26262140274, Training accuracy = 0.899999976158\n",
      "Iter 900, Minibatch Loss = 0.0179210714996, Training accuracy = 1.0\n",
      "Iter 1000, Minibatch Loss = 0.302306771278, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.0564922615886, Training accuracy = 1.0\n",
      "Iter 1200, Minibatch Loss = 0.0513093695045, Training accuracy = 1.0\n",
      "Iter 1300, Minibatch Loss = 0.190564066172, Training accuracy = 0.899999976158\n",
      "Iter 1400, Minibatch Loss = 0.207085877657, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.0190188828856, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.00716560706496, Training accuracy = 1.0\n",
      "Iter 1700, Minibatch Loss = 0.00370497303084, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.0129913594574, Training accuracy = 1.0\n",
      "Iter 1900, Minibatch Loss = 0.0237893294543, Training accuracy = 1.0\n",
      "Iter 2000, Minibatch Loss = 0.0209486857057, Training accuracy = 1.0\n",
      "Iter 2100, Minibatch Loss = 0.00573088601232, Training accuracy = 1.0\n",
      "Iter 2200, Minibatch Loss = 0.114864572883, Training accuracy = 0.899999976158\n",
      "Iter 2300, Minibatch Loss = 0.00667493790388, Training accuracy = 1.0\n",
      "Iter 2400, Minibatch Loss = 0.0126753244549, Training accuracy = 1.0\n",
      "Iter 2500, Minibatch Loss = 0.0257591716945, Training accuracy = 1.0\n",
      "Iter 2600, Minibatch Loss = 0.00993666611612, Training accuracy = 1.0\n",
      "Iter 2700, Minibatch Loss = 0.0467641353607, Training accuracy = 1.0\n",
      "Iter 2800, Minibatch Loss = 0.0857582837343, Training accuracy = 1.0\n",
      "Iter 2900, Minibatch Loss = 0.00266201724298, Training accuracy = 1.0\n",
      "Iter 3000, Minibatch Loss = 0.134443849325, Training accuracy = 0.899999976158\n",
      "Iter 3100, Minibatch Loss = 0.116462036967, Training accuracy = 0.899999976158\n",
      "Iter 3200, Minibatch Loss = 0.0854931473732, Training accuracy = 1.0\n",
      "Iter 3300, Minibatch Loss = 0.0694040358067, Training accuracy = 1.0\n",
      "Iter 3400, Minibatch Loss = 0.0168020240963, Training accuracy = 1.0\n",
      "Iter 3500, Minibatch Loss = 0.0676485523582, Training accuracy = 1.0\n",
      "Iter 3600, Minibatch Loss = 0.0248075854033, Training accuracy = 1.0\n",
      "Iter 3700, Minibatch Loss = 0.00430668145418, Training accuracy = 1.0\n",
      "Iter 3800, Minibatch Loss = 0.0581945292652, Training accuracy = 1.0\n",
      "Iter 3900, Minibatch Loss = 0.0151388216764, Training accuracy = 1.0\n",
      "Iter 4000, Minibatch Loss = 0.0952651649714, Training accuracy = 1.0\n",
      "Iter 4100, Minibatch Loss = 0.00277480110526, Training accuracy = 1.0\n",
      "Iter 4200, Minibatch Loss = 0.00269940355793, Training accuracy = 1.0\n",
      "Iter 100, Minibatch Loss = 0.00231943046674, Training accuracy = 1.0\n",
      "Iter 200, Minibatch Loss = 0.0125564411283, Training accuracy = 1.0\n",
      "Iter 300, Minibatch Loss = 0.00677087623626, Training accuracy = 1.0\n",
      "Iter 400, Minibatch Loss = 0.490257740021, Training accuracy = 0.899999976158\n",
      "Iter 500, Minibatch Loss = 0.00232973136008, Training accuracy = 1.0\n",
      "Iter 600, Minibatch Loss = 0.111708715558, Training accuracy = 1.0\n",
      "Iter 700, Minibatch Loss = 0.00680666882545, Training accuracy = 1.0\n",
      "Iter 800, Minibatch Loss = 0.241024881601, Training accuracy = 0.899999976158\n",
      "Iter 900, Minibatch Loss = 0.0140800671652, Training accuracy = 1.0\n",
      "Iter 1000, Minibatch Loss = 0.298144221306, Training accuracy = 0.899999976158\n",
      "Iter 1100, Minibatch Loss = 0.0341607816517, Training accuracy = 1.0\n",
      "Iter 1200, Minibatch Loss = 0.0337076969445, Training accuracy = 1.0\n",
      "Iter 1300, Minibatch Loss = 0.145189031959, Training accuracy = 0.899999976158\n",
      "Iter 1400, Minibatch Loss = 0.167192026973, Training accuracy = 0.899999976158\n",
      "Iter 1500, Minibatch Loss = 0.0168206468225, Training accuracy = 1.0\n",
      "Iter 1600, Minibatch Loss = 0.00566011667252, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1700, Minibatch Loss = 0.00287162349559, Training accuracy = 1.0\n",
      "Iter 1800, Minibatch Loss = 0.00901879929006, Training accuracy = 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7b07dc9c2bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        step = 1\n",
    "        while step*batch_size <= train_data.shape[0]:\n",
    "            xs, ys = train_data[(step-1)*batch_size:step*batch_size, :], train_label[(step-1)*batch_size:step*batch_size, :]\n",
    "            sess.run(optimizer, feed_dict={X:xs, y:ys})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss, acc = sess.run([cost,accuracy], feed_dict={X:xs, y:ys})\n",
    "                print(\"Iter {0}, Minibatch Loss = {1}, Training accuracy = {2}\".format(str(step),loss,acc))\n",
    "                \n",
    "            step += 1\n",
    "    print(\"Optimization Completed\")\n",
    "    test_labels = []\n",
    "    for i in range(1000):\n",
    "        xs, ys = test_data[i*28:(i+1)*28, :], test_data[i*28:(i+1)*28, 0:10]\n",
    "        pred_ = sess.run(label, feed_dict={X:xs, y:ys})\n",
    "        test_labels.extend(list(pred_))\n",
    "        \n",
    "f1 = open('label','wb')\n",
    "pickle.dump(test_labels, f1)\n",
    "f1.close()\n",
    "\n",
    "df = pd.DataFrame({'Label' : test_labels})\n",
    "df1 = pd.concat([pd.Series(range(1,28001), name='ImageId'), df[['Label']]], axis=1)\n",
    "df1.to_csv('ConvPool_X2.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
