{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\",\"all\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "train_data0 = pd.read_csv(\"all/train.csv\")\n",
    "print(train_data0.shape)\n",
    "train_data = np.array(train_data0.iloc[:, 1:785])\n",
    "train_label = np.array(train_data0.iloc[:,0])\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_label = to_categorical(train_label, num_classes=10)\n",
    "print(train_label[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_data0 = pd.read_csv(\"all/test.csv\")\n",
    "print(test_data0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(test_data0)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 4 0 0 7 3 5 3]\n",
      "is equivalent to :\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_data0.iloc[:,0])[:10])\n",
    "print('is equivalent to :')\n",
    "print(train_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   5  60 136 136 147 254 255\n",
      " 199 111  18   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  25 152 253 253 253 253 253 253 253 253 253 124   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 135 225 244 253 202 200\n",
      " 181 164 216 253 253 211 151   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  30 149  78   3   0   0   0  20 134 253 253 224   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  28 206 253 253 224   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  78 253 253 253\n",
      " 224   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   5  99 234 253 253 224   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  14 142 220 219 236\n",
      " 253 253 240 121   7   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  24 253 253 253 253 235 233 253 253 185  53   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8 150 194\n",
      " 194 194  53  40  97 253 253 170   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 122 253 253 170\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  55 237 253 253 170   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 130 253 253\n",
      " 253 170   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   4  12 120 193 253 253 214  28   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   7 153 253 253 253\n",
      " 253 212  30   0   0   0   0   0   0   0   0   0   0   0   0   0  33 136\n",
      "  70   6   0  27  67 186 253 253 253 253 234  31   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  26 231 253 253 191 183 223 253 253 253 253\n",
      " 172 216 112   0   0   0   0   0   0   0   0   0   0   0   0   0   0  36\n",
      " 215 253 253 253 253 253 253 253 253 253  47  25   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   5  87 223 253 253 253 244 152 223\n",
      " 223 109   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  67  50 176 148  78  16   0  12  12   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data[9])\n",
    "pixels = train_data[9].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = train_data[7].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = train_data[6].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_14:0' shape=() dtype=int32_ref>\n",
      "<tf.Variable 'Variable_15:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00005\n",
    "epoch = 40\n",
    "batch_size = 20\n",
    "\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "def conv2d(name, x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.elu(x, name=name)\n",
    "\n",
    "def maxpool2d(name, x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,k,k,1], padding = 'SAME')\n",
    "\n",
    "weights = {\n",
    "    'W1' : tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1)),\n",
    "    'W2' : tf.Variable(tf.truncated_normal([5,5,32,64], stddev=0.1)),\n",
    "    'W4' : tf.Variable(tf.truncated_normal([64*7*7,784],stddev=0.1)),\n",
    "    'Wo' : tf.Variable(tf.truncated_normal([784,n_classes], stddev=0.1))\n",
    "}\n",
    "a = tf.Variable(1)\n",
    "print(a)\n",
    "print(tf.Variable(tf.truncated_normal([5,5,1,32],stddev=0.1)))\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([32],stddev=0.1)),\n",
    "    'b2' : tf.Variable(tf.random_normal([64], stddev=0.1)),\n",
    "    'b4' : tf.Variable(tf.random_normal([784], stddev=0.1)),\n",
    "    'bo' : tf.Variable(tf.random_normal([n_classes], stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, weights , biases):\n",
    "    x = tf.reshape(X, [-1,28,28,1]) #padding\n",
    "    x = x/255 #normalization\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv2d('conv1', x, weights['W1'], biases['b1'])) \n",
    "    pool1 = maxpool2d('pool1', conv1, k=2)\n",
    "    drop1 = tf.layers.dropout(pool1, 0.7, True)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2d('conv2',drop1,weights['W2'],biases['b2']))\n",
    "    pool2 = maxpool2d('pool2',conv2,k=2)\n",
    "    drop2 = tf.layers.dropout(pool2,0.7,True)\n",
    "    \n",
    "    fc = tf.reshape(pool2, [-1, weights['W4'].get_shape().as_list()[0]])\n",
    "    fc = tf.add(tf.matmul(fc,weights['W4']), biases['b4'])\n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    a = tf.add(tf.matmul(fc, weights['Wo']), biases['bo'])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "label = tf.argmax(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(label, tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, Iter 100, Minibatch Loss = 1.27325558662, Training accuracy = 0.649999976158\n",
      "epoch 0, Iter 200, Minibatch Loss = 0.420457065105, Training accuracy = 0.899999976158\n",
      "epoch 0, Iter 300, Minibatch Loss = 0.188418358564, Training accuracy = 1.0\n",
      "epoch 0, Iter 400, Minibatch Loss = 0.394592136145, Training accuracy = 0.850000023842\n",
      "epoch 0, Iter 500, Minibatch Loss = 0.189359307289, Training accuracy = 0.949999988079\n",
      "epoch 0, Iter 600, Minibatch Loss = 0.392213612795, Training accuracy = 0.850000023842\n",
      "epoch 0, Iter 700, Minibatch Loss = 0.0672271251678, Training accuracy = 1.0\n",
      "epoch 0, Iter 800, Minibatch Loss = 0.0790810659528, Training accuracy = 1.0\n",
      "epoch 0, Iter 900, Minibatch Loss = 0.0772839188576, Training accuracy = 1.0\n",
      "epoch 0, Iter 1000, Minibatch Loss = 0.0337782502174, Training accuracy = 1.0\n",
      "epoch 0, Iter 1100, Minibatch Loss = 0.0686651617289, Training accuracy = 1.0\n",
      "epoch 0, Iter 1200, Minibatch Loss = 0.0580942258239, Training accuracy = 1.0\n",
      "epoch 0, Iter 1300, Minibatch Loss = 0.0260977353901, Training accuracy = 1.0\n",
      "epoch 0, Iter 1400, Minibatch Loss = 0.0302304588258, Training accuracy = 1.0\n",
      "epoch 0, Iter 1500, Minibatch Loss = 0.0628642588854, Training accuracy = 1.0\n",
      "epoch 0, Iter 1600, Minibatch Loss = 0.060021944344, Training accuracy = 1.0\n",
      "epoch 0, Iter 1700, Minibatch Loss = 0.0320399478078, Training accuracy = 1.0\n",
      "epoch 0, Iter 1800, Minibatch Loss = 0.0260192211717, Training accuracy = 1.0\n",
      "epoch 0, Iter 1900, Minibatch Loss = 0.0362109020352, Training accuracy = 1.0\n",
      "epoch 0, Iter 2000, Minibatch Loss = 0.0169424526393, Training accuracy = 1.0\n",
      "epoch 0, Iter 2100, Minibatch Loss = 0.0107955783606, Training accuracy = 1.0\n",
      "epoch 1, Iter 100, Minibatch Loss = 0.00641011307016, Training accuracy = 1.0\n",
      "epoch 1, Iter 200, Minibatch Loss = 0.0434263348579, Training accuracy = 0.949999988079\n",
      "epoch 1, Iter 300, Minibatch Loss = 0.0226236190647, Training accuracy = 1.0\n",
      "epoch 1, Iter 400, Minibatch Loss = 0.084071598947, Training accuracy = 0.949999988079\n",
      "epoch 1, Iter 500, Minibatch Loss = 0.0601926669478, Training accuracy = 1.0\n",
      "epoch 1, Iter 600, Minibatch Loss = 0.0488628558815, Training accuracy = 1.0\n",
      "epoch 1, Iter 700, Minibatch Loss = 0.0369099862874, Training accuracy = 1.0\n",
      "epoch 1, Iter 800, Minibatch Loss = 0.0169163327664, Training accuracy = 1.0\n",
      "epoch 1, Iter 900, Minibatch Loss = 0.0110442927107, Training accuracy = 1.0\n",
      "epoch 1, Iter 1000, Minibatch Loss = 0.00773629825562, Training accuracy = 1.0\n",
      "epoch 1, Iter 1100, Minibatch Loss = 0.0268814824522, Training accuracy = 1.0\n",
      "epoch 1, Iter 1200, Minibatch Loss = 0.0102647021413, Training accuracy = 1.0\n",
      "epoch 1, Iter 1300, Minibatch Loss = 0.00761369615793, Training accuracy = 1.0\n",
      "epoch 1, Iter 1400, Minibatch Loss = 0.014964225702, Training accuracy = 1.0\n",
      "epoch 1, Iter 1500, Minibatch Loss = 0.0225922837853, Training accuracy = 1.0\n",
      "epoch 1, Iter 1600, Minibatch Loss = 0.0281161423773, Training accuracy = 1.0\n",
      "epoch 1, Iter 1700, Minibatch Loss = 0.0101225404069, Training accuracy = 1.0\n",
      "epoch 1, Iter 1800, Minibatch Loss = 0.0103738326579, Training accuracy = 1.0\n",
      "epoch 1, Iter 1900, Minibatch Loss = 0.0193672962487, Training accuracy = 1.0\n",
      "epoch 1, Iter 2000, Minibatch Loss = 0.00882733333856, Training accuracy = 1.0\n",
      "epoch 1, Iter 2100, Minibatch Loss = 0.00432833936065, Training accuracy = 1.0\n",
      "epoch 2, Iter 100, Minibatch Loss = 0.00232783751562, Training accuracy = 1.0\n",
      "epoch 2, Iter 200, Minibatch Loss = 0.0628354400396, Training accuracy = 0.949999988079\n",
      "epoch 2, Iter 300, Minibatch Loss = 0.00871490966529, Training accuracy = 1.0\n",
      "epoch 2, Iter 400, Minibatch Loss = 0.035303466022, Training accuracy = 1.0\n",
      "epoch 2, Iter 500, Minibatch Loss = 0.0417899116874, Training accuracy = 1.0\n",
      "epoch 2, Iter 600, Minibatch Loss = 0.0158380623907, Training accuracy = 1.0\n",
      "epoch 2, Iter 700, Minibatch Loss = 0.0260922666639, Training accuracy = 1.0\n",
      "epoch 2, Iter 800, Minibatch Loss = 0.00771091645584, Training accuracy = 1.0\n",
      "epoch 2, Iter 900, Minibatch Loss = 0.00401231413707, Training accuracy = 1.0\n",
      "epoch 2, Iter 1000, Minibatch Loss = 0.0052585862577, Training accuracy = 1.0\n",
      "epoch 2, Iter 1100, Minibatch Loss = 0.0131324697286, Training accuracy = 1.0\n",
      "epoch 2, Iter 1200, Minibatch Loss = 0.00561907142401, Training accuracy = 1.0\n",
      "epoch 2, Iter 1300, Minibatch Loss = 0.00460485229269, Training accuracy = 1.0\n",
      "epoch 2, Iter 1400, Minibatch Loss = 0.0111589115113, Training accuracy = 1.0\n",
      "epoch 2, Iter 1500, Minibatch Loss = 0.011731329374, Training accuracy = 1.0\n",
      "epoch 2, Iter 1600, Minibatch Loss = 0.0121608506888, Training accuracy = 1.0\n",
      "epoch 2, Iter 1700, Minibatch Loss = 0.00410129176453, Training accuracy = 1.0\n",
      "epoch 2, Iter 1800, Minibatch Loss = 0.00703922146931, Training accuracy = 1.0\n",
      "epoch 2, Iter 1900, Minibatch Loss = 0.0122548816726, Training accuracy = 1.0\n",
      "epoch 2, Iter 2000, Minibatch Loss = 0.00670513603836, Training accuracy = 1.0\n",
      "epoch 2, Iter 2100, Minibatch Loss = 0.00222499063239, Training accuracy = 1.0\n",
      "epoch 3, Iter 100, Minibatch Loss = 0.00160800968297, Training accuracy = 1.0\n",
      "epoch 3, Iter 200, Minibatch Loss = 0.0438573025167, Training accuracy = 0.949999988079\n",
      "epoch 3, Iter 300, Minibatch Loss = 0.00371492654085, Training accuracy = 1.0\n",
      "epoch 3, Iter 400, Minibatch Loss = 0.0150161255151, Training accuracy = 1.0\n",
      "epoch 3, Iter 500, Minibatch Loss = 0.0212650895119, Training accuracy = 1.0\n",
      "epoch 3, Iter 600, Minibatch Loss = 0.00629580300301, Training accuracy = 1.0\n",
      "epoch 3, Iter 700, Minibatch Loss = 0.0210918337107, Training accuracy = 1.0\n",
      "epoch 3, Iter 800, Minibatch Loss = 0.00484447646886, Training accuracy = 1.0\n",
      "epoch 3, Iter 900, Minibatch Loss = 0.00293354433961, Training accuracy = 1.0\n",
      "epoch 3, Iter 1000, Minibatch Loss = 0.00346993957646, Training accuracy = 1.0\n",
      "epoch 3, Iter 1100, Minibatch Loss = 0.00785616412759, Training accuracy = 1.0\n",
      "epoch 3, Iter 1200, Minibatch Loss = 0.00336888874881, Training accuracy = 1.0\n",
      "epoch 3, Iter 1300, Minibatch Loss = 0.00359629397281, Training accuracy = 1.0\n",
      "epoch 3, Iter 1400, Minibatch Loss = 0.00834813062102, Training accuracy = 1.0\n",
      "epoch 3, Iter 1500, Minibatch Loss = 0.00655809929594, Training accuracy = 1.0\n",
      "epoch 3, Iter 1600, Minibatch Loss = 0.00878833979368, Training accuracy = 1.0\n",
      "epoch 3, Iter 1700, Minibatch Loss = 0.0023576724343, Training accuracy = 1.0\n",
      "epoch 3, Iter 1800, Minibatch Loss = 0.00487626483664, Training accuracy = 1.0\n",
      "epoch 3, Iter 1900, Minibatch Loss = 0.00783327128738, Training accuracy = 1.0\n",
      "epoch 3, Iter 2000, Minibatch Loss = 0.00531463138759, Training accuracy = 1.0\n",
      "epoch 3, Iter 2100, Minibatch Loss = 0.00138918193989, Training accuracy = 1.0\n",
      "epoch 4, Iter 100, Minibatch Loss = 0.00113361363765, Training accuracy = 1.0\n",
      "epoch 4, Iter 200, Minibatch Loss = 0.0288188494742, Training accuracy = 1.0\n",
      "epoch 4, Iter 300, Minibatch Loss = 0.00236614677124, Training accuracy = 1.0\n",
      "epoch 4, Iter 400, Minibatch Loss = 0.0087064076215, Training accuracy = 1.0\n",
      "epoch 4, Iter 500, Minibatch Loss = 0.0103405434638, Training accuracy = 1.0\n",
      "epoch 4, Iter 600, Minibatch Loss = 0.00255079148337, Training accuracy = 1.0\n",
      "epoch 4, Iter 700, Minibatch Loss = 0.0125812841579, Training accuracy = 1.0\n",
      "epoch 4, Iter 800, Minibatch Loss = 0.00311800325289, Training accuracy = 1.0\n",
      "epoch 4, Iter 900, Minibatch Loss = 0.00228363880888, Training accuracy = 1.0\n",
      "epoch 4, Iter 1000, Minibatch Loss = 0.00196074252017, Training accuracy = 1.0\n",
      "epoch 4, Iter 1100, Minibatch Loss = 0.00513841677457, Training accuracy = 1.0\n",
      "epoch 4, Iter 1200, Minibatch Loss = 0.00180760608055, Training accuracy = 1.0\n",
      "epoch 4, Iter 1300, Minibatch Loss = 0.00300720147789, Training accuracy = 1.0\n",
      "epoch 4, Iter 1400, Minibatch Loss = 0.0057875206694, Training accuracy = 1.0\n",
      "epoch 4, Iter 1500, Minibatch Loss = 0.0050044702366, Training accuracy = 1.0\n",
      "epoch 4, Iter 1600, Minibatch Loss = 0.00591198075563, Training accuracy = 1.0\n",
      "epoch 4, Iter 1700, Minibatch Loss = 0.00148845952936, Training accuracy = 1.0\n",
      "epoch 4, Iter 1800, Minibatch Loss = 0.00346583989449, Training accuracy = 1.0\n",
      "epoch 4, Iter 1900, Minibatch Loss = 0.00627632904798, Training accuracy = 1.0\n",
      "epoch 4, Iter 2000, Minibatch Loss = 0.00431707222015, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, Iter 2100, Minibatch Loss = 0.00102126295678, Training accuracy = 1.0\n",
      "epoch 5, Iter 100, Minibatch Loss = 0.000874911434948, Training accuracy = 1.0\n",
      "epoch 5, Iter 200, Minibatch Loss = 0.0197385083884, Training accuracy = 1.0\n",
      "epoch 5, Iter 300, Minibatch Loss = 0.00168029346969, Training accuracy = 1.0\n",
      "epoch 5, Iter 400, Minibatch Loss = 0.00538434181362, Training accuracy = 1.0\n",
      "epoch 5, Iter 500, Minibatch Loss = 0.00605476740748, Training accuracy = 1.0\n",
      "epoch 5, Iter 600, Minibatch Loss = 0.00154888839461, Training accuracy = 1.0\n",
      "epoch 5, Iter 700, Minibatch Loss = 0.00783812440932, Training accuracy = 1.0\n",
      "epoch 5, Iter 800, Minibatch Loss = 0.00248224870302, Training accuracy = 1.0\n",
      "epoch 5, Iter 900, Minibatch Loss = 0.00166831165552, Training accuracy = 1.0\n",
      "epoch 5, Iter 1000, Minibatch Loss = 0.00103256944567, Training accuracy = 1.0\n",
      "epoch 5, Iter 1100, Minibatch Loss = 0.00332526420243, Training accuracy = 1.0\n",
      "epoch 5, Iter 1200, Minibatch Loss = 0.000890120049007, Training accuracy = 1.0\n",
      "epoch 5, Iter 1300, Minibatch Loss = 0.00195824052207, Training accuracy = 1.0\n",
      "epoch 5, Iter 1400, Minibatch Loss = 0.00308056874201, Training accuracy = 1.0\n",
      "epoch 5, Iter 1500, Minibatch Loss = 0.00365123944357, Training accuracy = 1.0\n",
      "epoch 5, Iter 1600, Minibatch Loss = 0.00424127560109, Training accuracy = 1.0\n",
      "epoch 5, Iter 1700, Minibatch Loss = 0.000978930736892, Training accuracy = 1.0\n",
      "epoch 5, Iter 1800, Minibatch Loss = 0.00251366547309, Training accuracy = 1.0\n",
      "epoch 5, Iter 1900, Minibatch Loss = 0.00657310988754, Training accuracy = 1.0\n",
      "epoch 5, Iter 2000, Minibatch Loss = 0.00340238516219, Training accuracy = 1.0\n",
      "epoch 5, Iter 2100, Minibatch Loss = 0.000800396490376, Training accuracy = 1.0\n",
      "epoch 6, Iter 100, Minibatch Loss = 0.000785078271292, Training accuracy = 1.0\n",
      "epoch 6, Iter 200, Minibatch Loss = 0.0102104153484, Training accuracy = 1.0\n",
      "epoch 6, Iter 300, Minibatch Loss = 0.00117227667943, Training accuracy = 1.0\n",
      "epoch 6, Iter 400, Minibatch Loss = 0.00364034622908, Training accuracy = 1.0\n",
      "epoch 6, Iter 500, Minibatch Loss = 0.00397900026292, Training accuracy = 1.0\n",
      "epoch 6, Iter 600, Minibatch Loss = 0.00119296472985, Training accuracy = 1.0\n",
      "epoch 6, Iter 700, Minibatch Loss = 0.00488142762333, Training accuracy = 1.0\n",
      "epoch 6, Iter 800, Minibatch Loss = 0.00175177433994, Training accuracy = 1.0\n",
      "epoch 6, Iter 900, Minibatch Loss = 0.00131371081807, Training accuracy = 1.0\n",
      "epoch 6, Iter 1000, Minibatch Loss = 0.000795177649707, Training accuracy = 1.0\n",
      "epoch 6, Iter 1100, Minibatch Loss = 0.00253957090899, Training accuracy = 1.0\n",
      "epoch 6, Iter 1200, Minibatch Loss = 0.000501275178976, Training accuracy = 1.0\n",
      "epoch 6, Iter 1300, Minibatch Loss = 0.00112463987898, Training accuracy = 1.0\n",
      "epoch 6, Iter 1400, Minibatch Loss = 0.00177166366484, Training accuracy = 1.0\n",
      "epoch 6, Iter 1500, Minibatch Loss = 0.00263128196821, Training accuracy = 1.0\n",
      "epoch 6, Iter 1600, Minibatch Loss = 0.00329146604054, Training accuracy = 1.0\n",
      "epoch 6, Iter 1700, Minibatch Loss = 0.000741318159271, Training accuracy = 1.0\n",
      "epoch 6, Iter 1800, Minibatch Loss = 0.00188092666212, Training accuracy = 1.0\n",
      "epoch 6, Iter 1900, Minibatch Loss = 0.00557621149346, Training accuracy = 1.0\n",
      "epoch 6, Iter 2000, Minibatch Loss = 0.00292824441567, Training accuracy = 1.0\n",
      "epoch 6, Iter 2100, Minibatch Loss = 0.000719939533155, Training accuracy = 1.0\n",
      "epoch 7, Iter 100, Minibatch Loss = 0.000549932534341, Training accuracy = 1.0\n",
      "epoch 7, Iter 200, Minibatch Loss = 0.00514317862689, Training accuracy = 1.0\n",
      "epoch 7, Iter 300, Minibatch Loss = 0.000881583429873, Training accuracy = 1.0\n",
      "epoch 7, Iter 400, Minibatch Loss = 0.00255220732652, Training accuracy = 1.0\n",
      "epoch 7, Iter 500, Minibatch Loss = 0.00218452466652, Training accuracy = 1.0\n",
      "epoch 7, Iter 600, Minibatch Loss = 0.000796387437731, Training accuracy = 1.0\n",
      "epoch 7, Iter 700, Minibatch Loss = 0.00240580248646, Training accuracy = 1.0\n",
      "epoch 7, Iter 800, Minibatch Loss = 0.00151082722005, Training accuracy = 1.0\n",
      "epoch 7, Iter 900, Minibatch Loss = 0.00104347988963, Training accuracy = 1.0\n",
      "epoch 7, Iter 1000, Minibatch Loss = 0.000573346507736, Training accuracy = 1.0\n",
      "epoch 7, Iter 1100, Minibatch Loss = 0.00201302883215, Training accuracy = 1.0\n",
      "epoch 7, Iter 1200, Minibatch Loss = 0.000327571935486, Training accuracy = 1.0\n",
      "epoch 7, Iter 1300, Minibatch Loss = 0.000646252883598, Training accuracy = 1.0\n",
      "epoch 7, Iter 1400, Minibatch Loss = 0.00118074787315, Training accuracy = 1.0\n",
      "epoch 7, Iter 1500, Minibatch Loss = 0.00196400843561, Training accuracy = 1.0\n",
      "epoch 7, Iter 1600, Minibatch Loss = 0.00264147017151, Training accuracy = 1.0\n",
      "epoch 7, Iter 1700, Minibatch Loss = 0.000499079818837, Training accuracy = 1.0\n",
      "epoch 7, Iter 1800, Minibatch Loss = 0.00129589415155, Training accuracy = 1.0\n",
      "epoch 7, Iter 1900, Minibatch Loss = 0.00473347213119, Training accuracy = 1.0\n",
      "epoch 7, Iter 2000, Minibatch Loss = 0.00215153535828, Training accuracy = 1.0\n",
      "epoch 7, Iter 2100, Minibatch Loss = 0.000627909612376, Training accuracy = 1.0\n",
      "epoch 8, Iter 100, Minibatch Loss = 0.00026513155899, Training accuracy = 1.0\n",
      "epoch 8, Iter 200, Minibatch Loss = 0.00297518749721, Training accuracy = 1.0\n",
      "epoch 8, Iter 300, Minibatch Loss = 0.000787190161645, Training accuracy = 1.0\n",
      "epoch 8, Iter 400, Minibatch Loss = 0.00190601346549, Training accuracy = 1.0\n",
      "epoch 8, Iter 500, Minibatch Loss = 0.00100747938268, Training accuracy = 1.0\n",
      "epoch 8, Iter 600, Minibatch Loss = 0.000569673196878, Training accuracy = 1.0\n",
      "epoch 8, Iter 700, Minibatch Loss = 0.00132997857872, Training accuracy = 1.0\n",
      "epoch 8, Iter 800, Minibatch Loss = 0.00137501920108, Training accuracy = 1.0\n",
      "epoch 8, Iter 900, Minibatch Loss = 0.000747919082642, Training accuracy = 1.0\n",
      "epoch 8, Iter 1000, Minibatch Loss = 0.000369091692846, Training accuracy = 1.0\n",
      "epoch 8, Iter 1100, Minibatch Loss = 0.00152802444063, Training accuracy = 1.0\n",
      "epoch 8, Iter 1200, Minibatch Loss = 0.000221738053369, Training accuracy = 1.0\n",
      "epoch 8, Iter 1300, Minibatch Loss = 0.000391577224946, Training accuracy = 1.0\n",
      "epoch 8, Iter 1400, Minibatch Loss = 0.00081507943105, Training accuracy = 1.0\n",
      "epoch 8, Iter 1500, Minibatch Loss = 0.00149177992716, Training accuracy = 1.0\n",
      "epoch 8, Iter 1600, Minibatch Loss = 0.00211998051964, Training accuracy = 1.0\n",
      "epoch 8, Iter 1700, Minibatch Loss = 0.000385538296541, Training accuracy = 1.0\n",
      "epoch 8, Iter 1800, Minibatch Loss = 0.000828595715575, Training accuracy = 1.0\n",
      "epoch 8, Iter 1900, Minibatch Loss = 0.00426309276372, Training accuracy = 1.0\n",
      "epoch 8, Iter 2000, Minibatch Loss = 0.00144618679769, Training accuracy = 1.0\n",
      "epoch 8, Iter 2100, Minibatch Loss = 0.000447423983132, Training accuracy = 1.0\n",
      "epoch 9, Iter 100, Minibatch Loss = 0.000183151336387, Training accuracy = 1.0\n",
      "epoch 9, Iter 200, Minibatch Loss = 0.00174764823169, Training accuracy = 1.0\n",
      "epoch 9, Iter 300, Minibatch Loss = 0.000645783613436, Training accuracy = 1.0\n",
      "epoch 9, Iter 400, Minibatch Loss = 0.00142246217001, Training accuracy = 1.0\n",
      "epoch 9, Iter 500, Minibatch Loss = 0.00054142519366, Training accuracy = 1.0\n",
      "epoch 9, Iter 600, Minibatch Loss = 0.000368904875359, Training accuracy = 1.0\n",
      "epoch 9, Iter 700, Minibatch Loss = 0.000991795444861, Training accuracy = 1.0\n",
      "epoch 9, Iter 800, Minibatch Loss = 0.0011754934676, Training accuracy = 1.0\n",
      "epoch 9, Iter 900, Minibatch Loss = 0.000506214448251, Training accuracy = 1.0\n",
      "epoch 9, Iter 1000, Minibatch Loss = 0.000215123829548, Training accuracy = 1.0\n",
      "epoch 9, Iter 1100, Minibatch Loss = 0.00120529718697, Training accuracy = 1.0\n",
      "epoch 9, Iter 1200, Minibatch Loss = 0.000146108446643, Training accuracy = 1.0\n",
      "epoch 9, Iter 1300, Minibatch Loss = 0.000250360724749, Training accuracy = 1.0\n",
      "epoch 9, Iter 1400, Minibatch Loss = 0.000528901873622, Training accuracy = 1.0\n",
      "epoch 9, Iter 1500, Minibatch Loss = 0.00100341043435, Training accuracy = 1.0\n",
      "epoch 9, Iter 1600, Minibatch Loss = 0.00175301951822, Training accuracy = 1.0\n",
      "epoch 9, Iter 1700, Minibatch Loss = 0.000330390321324, Training accuracy = 1.0\n",
      "epoch 9, Iter 1800, Minibatch Loss = 0.000550672819372, Training accuracy = 1.0\n",
      "epoch 9, Iter 1900, Minibatch Loss = 0.00370099698193, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, Iter 2000, Minibatch Loss = 0.000961897254456, Training accuracy = 1.0\n",
      "epoch 9, Iter 2100, Minibatch Loss = 0.000351207330823, Training accuracy = 1.0\n",
      "epoch 10, Iter 100, Minibatch Loss = 0.00013797050633, Training accuracy = 1.0\n",
      "epoch 10, Iter 200, Minibatch Loss = 0.000927174813114, Training accuracy = 1.0\n",
      "epoch 10, Iter 300, Minibatch Loss = 0.000477622408653, Training accuracy = 1.0\n",
      "epoch 10, Iter 400, Minibatch Loss = 0.00104127754457, Training accuracy = 1.0\n",
      "epoch 10, Iter 500, Minibatch Loss = 0.000250023556873, Training accuracy = 1.0\n",
      "epoch 10, Iter 600, Minibatch Loss = 0.000252250407357, Training accuracy = 1.0\n",
      "epoch 10, Iter 700, Minibatch Loss = 0.000808101147413, Training accuracy = 1.0\n",
      "epoch 10, Iter 800, Minibatch Loss = 0.0009902685415, Training accuracy = 1.0\n",
      "epoch 10, Iter 900, Minibatch Loss = 0.000296875601634, Training accuracy = 1.0\n",
      "epoch 10, Iter 1000, Minibatch Loss = 0.000108092601295, Training accuracy = 1.0\n",
      "epoch 10, Iter 1100, Minibatch Loss = 0.000895927543752, Training accuracy = 1.0\n",
      "epoch 10, Iter 1200, Minibatch Loss = 9.8308584711e-05, Training accuracy = 1.0\n",
      "epoch 10, Iter 1300, Minibatch Loss = 0.000180120143341, Training accuracy = 1.0\n",
      "epoch 10, Iter 1400, Minibatch Loss = 0.000392740825191, Training accuracy = 1.0\n",
      "epoch 10, Iter 1500, Minibatch Loss = 0.00070131290704, Training accuracy = 1.0\n",
      "epoch 10, Iter 1600, Minibatch Loss = 0.00134235108271, Training accuracy = 1.0\n",
      "epoch 10, Iter 1700, Minibatch Loss = 0.000236355088418, Training accuracy = 1.0\n",
      "epoch 10, Iter 1800, Minibatch Loss = 0.000386737112422, Training accuracy = 1.0\n",
      "epoch 10, Iter 1900, Minibatch Loss = 0.00296941073611, Training accuracy = 1.0\n",
      "epoch 10, Iter 2000, Minibatch Loss = 0.000677503412589, Training accuracy = 1.0\n",
      "epoch 10, Iter 2100, Minibatch Loss = 0.000262780726189, Training accuracy = 1.0\n",
      "epoch 11, Iter 100, Minibatch Loss = 0.000110753593617, Training accuracy = 1.0\n",
      "epoch 11, Iter 200, Minibatch Loss = 0.00036137906136, Training accuracy = 1.0\n",
      "epoch 11, Iter 300, Minibatch Loss = 0.000454246852314, Training accuracy = 1.0\n",
      "epoch 11, Iter 400, Minibatch Loss = 0.000808332872111, Training accuracy = 1.0\n",
      "epoch 11, Iter 500, Minibatch Loss = 0.00012149792019, Training accuracy = 1.0\n",
      "epoch 11, Iter 600, Minibatch Loss = 0.000192397128558, Training accuracy = 1.0\n",
      "epoch 11, Iter 700, Minibatch Loss = 0.000517362379469, Training accuracy = 1.0\n",
      "epoch 11, Iter 800, Minibatch Loss = 0.000851248682011, Training accuracy = 1.0\n",
      "epoch 11, Iter 900, Minibatch Loss = 0.000203900781344, Training accuracy = 1.0\n",
      "epoch 11, Iter 1000, Minibatch Loss = 6.7864995799e-05, Training accuracy = 1.0\n",
      "epoch 11, Iter 1100, Minibatch Loss = 0.000649155757856, Training accuracy = 1.0\n",
      "epoch 11, Iter 1200, Minibatch Loss = 7.1579903306e-05, Training accuracy = 1.0\n",
      "epoch 11, Iter 1300, Minibatch Loss = 0.000181703158887, Training accuracy = 1.0\n",
      "epoch 11, Iter 1400, Minibatch Loss = 0.00027123367181, Training accuracy = 1.0\n",
      "epoch 11, Iter 1500, Minibatch Loss = 0.000595409306698, Training accuracy = 1.0\n",
      "epoch 11, Iter 1600, Minibatch Loss = 0.000922816980164, Training accuracy = 1.0\n",
      "epoch 11, Iter 1700, Minibatch Loss = 0.00016303229495, Training accuracy = 1.0\n",
      "epoch 11, Iter 1800, Minibatch Loss = 0.000262080226094, Training accuracy = 1.0\n",
      "epoch 11, Iter 1900, Minibatch Loss = 0.00241130404174, Training accuracy = 1.0\n",
      "epoch 11, Iter 2000, Minibatch Loss = 0.000547195086256, Training accuracy = 1.0\n",
      "epoch 11, Iter 2100, Minibatch Loss = 0.000167365957168, Training accuracy = 1.0\n",
      "epoch 12, Iter 100, Minibatch Loss = 0.000108879154141, Training accuracy = 1.0\n",
      "epoch 12, Iter 200, Minibatch Loss = 0.000179717186256, Training accuracy = 1.0\n",
      "epoch 12, Iter 300, Minibatch Loss = 0.000390228524338, Training accuracy = 1.0\n",
      "epoch 12, Iter 400, Minibatch Loss = 0.000659323472064, Training accuracy = 1.0\n",
      "epoch 12, Iter 500, Minibatch Loss = 6.0258731537e-05, Training accuracy = 1.0\n",
      "epoch 12, Iter 600, Minibatch Loss = 0.000148667415488, Training accuracy = 1.0\n",
      "epoch 12, Iter 700, Minibatch Loss = 0.000355634547304, Training accuracy = 1.0\n",
      "epoch 12, Iter 800, Minibatch Loss = 0.000652578659356, Training accuracy = 1.0\n",
      "epoch 12, Iter 900, Minibatch Loss = 0.000129238847876, Training accuracy = 1.0\n",
      "epoch 12, Iter 1000, Minibatch Loss = 5.19728273503e-05, Training accuracy = 1.0\n",
      "epoch 12, Iter 1100, Minibatch Loss = 0.000463601114461, Training accuracy = 1.0\n",
      "epoch 12, Iter 1200, Minibatch Loss = 4.97469736729e-05, Training accuracy = 1.0\n",
      "epoch 12, Iter 1300, Minibatch Loss = 0.000145983503899, Training accuracy = 1.0\n",
      "epoch 12, Iter 1400, Minibatch Loss = 0.000203934963793, Training accuracy = 1.0\n",
      "epoch 12, Iter 1500, Minibatch Loss = 0.00046795286471, Training accuracy = 1.0\n",
      "epoch 12, Iter 1600, Minibatch Loss = 0.000636543321889, Training accuracy = 1.0\n",
      "epoch 12, Iter 1700, Minibatch Loss = 0.000136970702442, Training accuracy = 1.0\n",
      "epoch 12, Iter 1800, Minibatch Loss = 0.000198690264369, Training accuracy = 1.0\n",
      "epoch 12, Iter 1900, Minibatch Loss = 0.00212215608917, Training accuracy = 1.0\n",
      "epoch 12, Iter 2000, Minibatch Loss = 0.000401030818466, Training accuracy = 1.0\n",
      "epoch 12, Iter 2100, Minibatch Loss = 0.000113632690045, Training accuracy = 1.0\n",
      "epoch 13, Iter 100, Minibatch Loss = 9.75004877546e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 200, Minibatch Loss = 0.000100941302662, Training accuracy = 1.0\n",
      "epoch 13, Iter 300, Minibatch Loss = 0.000311909010634, Training accuracy = 1.0\n",
      "epoch 13, Iter 400, Minibatch Loss = 0.000484931370011, Training accuracy = 1.0\n",
      "epoch 13, Iter 500, Minibatch Loss = 3.07052687276e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 600, Minibatch Loss = 8.74645847944e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 700, Minibatch Loss = 0.000266357033979, Training accuracy = 1.0\n",
      "epoch 13, Iter 800, Minibatch Loss = 0.000431677734014, Training accuracy = 1.0\n",
      "epoch 13, Iter 900, Minibatch Loss = 0.000103367317934, Training accuracy = 1.0\n",
      "epoch 13, Iter 1000, Minibatch Loss = 5.00695605297e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 1100, Minibatch Loss = 0.000334157753969, Training accuracy = 1.0\n",
      "epoch 13, Iter 1200, Minibatch Loss = 3.33942734869e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 1300, Minibatch Loss = 0.000155675690621, Training accuracy = 1.0\n",
      "epoch 13, Iter 1400, Minibatch Loss = 0.00014228267537, Training accuracy = 1.0\n",
      "epoch 13, Iter 1500, Minibatch Loss = 0.000365775224054, Training accuracy = 1.0\n",
      "epoch 13, Iter 1600, Minibatch Loss = 0.00044818938477, Training accuracy = 1.0\n",
      "epoch 13, Iter 1700, Minibatch Loss = 8.27274197945e-05, Training accuracy = 1.0\n",
      "epoch 13, Iter 1800, Minibatch Loss = 0.00010556903726, Training accuracy = 1.0\n",
      "epoch 13, Iter 1900, Minibatch Loss = 0.00154864729848, Training accuracy = 1.0\n",
      "epoch 13, Iter 2000, Minibatch Loss = 0.000301972031593, Training accuracy = 1.0\n",
      "epoch 13, Iter 2100, Minibatch Loss = 6.24803869869e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 100, Minibatch Loss = 6.81499805069e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 200, Minibatch Loss = 4.38263450633e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 300, Minibatch Loss = 0.000195352273295, Training accuracy = 1.0\n",
      "epoch 14, Iter 400, Minibatch Loss = 0.000362523482181, Training accuracy = 1.0\n",
      "epoch 14, Iter 500, Minibatch Loss = 1.65216315509e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 600, Minibatch Loss = 4.99789712194e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 700, Minibatch Loss = 0.000277515151538, Training accuracy = 1.0\n",
      "epoch 14, Iter 800, Minibatch Loss = 0.000363397033652, Training accuracy = 1.0\n",
      "epoch 14, Iter 900, Minibatch Loss = 8.10220371932e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 1000, Minibatch Loss = 5.20925859746e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 1100, Minibatch Loss = 0.00020826747641, Training accuracy = 1.0\n",
      "epoch 14, Iter 1200, Minibatch Loss = 2.87037746602e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 1300, Minibatch Loss = 0.000154947949341, Training accuracy = 1.0\n",
      "epoch 14, Iter 1400, Minibatch Loss = 0.00010194722563, Training accuracy = 1.0\n",
      "epoch 14, Iter 1500, Minibatch Loss = 0.000241035682848, Training accuracy = 1.0\n",
      "epoch 14, Iter 1600, Minibatch Loss = 0.000312076968839, Training accuracy = 1.0\n",
      "epoch 14, Iter 1700, Minibatch Loss = 4.90679631184e-05, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, Iter 1800, Minibatch Loss = 9.10231174203e-05, Training accuracy = 1.0\n",
      "epoch 14, Iter 1900, Minibatch Loss = 0.00122929620557, Training accuracy = 1.0\n",
      "epoch 14, Iter 2000, Minibatch Loss = 0.000214397063246, Training accuracy = 1.0\n",
      "epoch 14, Iter 2100, Minibatch Loss = 3.29466056428e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 100, Minibatch Loss = 4.96544707858e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 200, Minibatch Loss = 1.78603968379e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 300, Minibatch Loss = 0.000141654149047, Training accuracy = 1.0\n",
      "epoch 15, Iter 400, Minibatch Loss = 0.000278534862446, Training accuracy = 1.0\n",
      "epoch 15, Iter 500, Minibatch Loss = 1.02040621641e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 600, Minibatch Loss = 3.61364218406e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 700, Minibatch Loss = 0.000156374109793, Training accuracy = 1.0\n",
      "epoch 15, Iter 800, Minibatch Loss = 0.000276827224297, Training accuracy = 1.0\n",
      "epoch 15, Iter 900, Minibatch Loss = 4.98284571222e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1000, Minibatch Loss = 2.80227395706e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1100, Minibatch Loss = 0.000139723953907, Training accuracy = 1.0\n",
      "epoch 15, Iter 1200, Minibatch Loss = 2.15281088458e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1300, Minibatch Loss = 0.000152562526637, Training accuracy = 1.0\n",
      "epoch 15, Iter 1400, Minibatch Loss = 6.43618404865e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1500, Minibatch Loss = 0.000147140017361, Training accuracy = 1.0\n",
      "epoch 15, Iter 1600, Minibatch Loss = 0.000247194519034, Training accuracy = 1.0\n",
      "epoch 15, Iter 1700, Minibatch Loss = 2.47155057878e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1800, Minibatch Loss = 6.50645815767e-05, Training accuracy = 1.0\n",
      "epoch 15, Iter 1900, Minibatch Loss = 0.000849420088343, Training accuracy = 1.0\n",
      "epoch 15, Iter 2000, Minibatch Loss = 0.000158980532433, Training accuracy = 1.0\n",
      "epoch 15, Iter 2100, Minibatch Loss = 1.82007697731e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 100, Minibatch Loss = 4.20184915129e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 200, Minibatch Loss = 8.56447331898e-06, Training accuracy = 1.0\n",
      "epoch 16, Iter 300, Minibatch Loss = 9.61638288572e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 400, Minibatch Loss = 0.000252468686085, Training accuracy = 1.0\n",
      "epoch 16, Iter 500, Minibatch Loss = 7.76034721639e-06, Training accuracy = 1.0\n",
      "epoch 16, Iter 600, Minibatch Loss = 2.40577282966e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 700, Minibatch Loss = 8.58813073137e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 800, Minibatch Loss = 0.000229794110055, Training accuracy = 1.0\n",
      "epoch 16, Iter 900, Minibatch Loss = 3.05365938402e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1000, Minibatch Loss = 1.75881014002e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1100, Minibatch Loss = 7.49536993681e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1200, Minibatch Loss = 1.58839939104e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1300, Minibatch Loss = 0.000166378304129, Training accuracy = 1.0\n",
      "epoch 16, Iter 1400, Minibatch Loss = 4.69705919386e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1500, Minibatch Loss = 0.00018197283498, Training accuracy = 1.0\n",
      "epoch 16, Iter 1600, Minibatch Loss = 0.000159437448019, Training accuracy = 1.0\n",
      "epoch 16, Iter 1700, Minibatch Loss = 1.55140805873e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1800, Minibatch Loss = 4.42483506049e-05, Training accuracy = 1.0\n",
      "epoch 16, Iter 1900, Minibatch Loss = 0.000691967725288, Training accuracy = 1.0\n",
      "epoch 16, Iter 2000, Minibatch Loss = 0.000104139988252, Training accuracy = 1.0\n",
      "epoch 16, Iter 2100, Minibatch Loss = 1.12643574539e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 100, Minibatch Loss = 2.9931868994e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 200, Minibatch Loss = 5.35221533937e-06, Training accuracy = 1.0\n",
      "epoch 17, Iter 300, Minibatch Loss = 2.81733518932e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 400, Minibatch Loss = 0.000176038331119, Training accuracy = 1.0\n",
      "epoch 17, Iter 500, Minibatch Loss = 5.32260764885e-06, Training accuracy = 1.0\n",
      "epoch 17, Iter 600, Minibatch Loss = 1.89036036318e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 700, Minibatch Loss = 6.03702319495e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 800, Minibatch Loss = 0.000220838614041, Training accuracy = 1.0\n",
      "epoch 17, Iter 900, Minibatch Loss = 2.62098710664e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1000, Minibatch Loss = 1.26355562315e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1100, Minibatch Loss = 5.38077365491e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1200, Minibatch Loss = 1.13126216092e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1300, Minibatch Loss = 0.000175191584276, Training accuracy = 1.0\n",
      "epoch 17, Iter 1400, Minibatch Loss = 4.0808256017e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1500, Minibatch Loss = 0.000183680822374, Training accuracy = 1.0\n",
      "epoch 17, Iter 1600, Minibatch Loss = 0.000106894367491, Training accuracy = 1.0\n",
      "epoch 17, Iter 1700, Minibatch Loss = 1.29512263811e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1800, Minibatch Loss = 3.19857645081e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 1900, Minibatch Loss = 0.000428237079177, Training accuracy = 1.0\n",
      "epoch 17, Iter 2000, Minibatch Loss = 8.38921259856e-05, Training accuracy = 1.0\n",
      "epoch 17, Iter 2100, Minibatch Loss = 6.71714815326e-06, Training accuracy = 1.0\n",
      "epoch 18, Iter 100, Minibatch Loss = 1.78727004823e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 200, Minibatch Loss = 5.73960051042e-06, Training accuracy = 1.0\n",
      "epoch 18, Iter 300, Minibatch Loss = 1.3278266124e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 400, Minibatch Loss = 0.000151831889525, Training accuracy = 1.0\n",
      "epoch 18, Iter 500, Minibatch Loss = 6.09740982327e-06, Training accuracy = 1.0\n",
      "epoch 18, Iter 600, Minibatch Loss = 1.41007958518e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 700, Minibatch Loss = 4.33650748164e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 800, Minibatch Loss = 0.000183946292964, Training accuracy = 1.0\n",
      "epoch 18, Iter 900, Minibatch Loss = 3.27149537043e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1000, Minibatch Loss = 1.17356885312e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1100, Minibatch Loss = 4.95435670018e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1200, Minibatch Loss = 8.63055811351e-06, Training accuracy = 1.0\n",
      "epoch 18, Iter 1300, Minibatch Loss = 0.000201045841095, Training accuracy = 1.0\n",
      "epoch 18, Iter 1400, Minibatch Loss = 2.66808838205e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1500, Minibatch Loss = 0.000153771747136, Training accuracy = 1.0\n",
      "epoch 18, Iter 1600, Minibatch Loss = 7.20550160622e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1700, Minibatch Loss = 1.18783291327e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1800, Minibatch Loss = 2.00015529117e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 1900, Minibatch Loss = 0.000334463227773, Training accuracy = 1.0\n",
      "epoch 18, Iter 2000, Minibatch Loss = 7.64059368521e-05, Training accuracy = 1.0\n",
      "epoch 18, Iter 2100, Minibatch Loss = 3.3258777421e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 100, Minibatch Loss = 1.57811173267e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 200, Minibatch Loss = 3.21258744407e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 300, Minibatch Loss = 2.14055453398e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 400, Minibatch Loss = 0.000114550894068, Training accuracy = 1.0\n",
      "epoch 19, Iter 500, Minibatch Loss = 6.63977561999e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 600, Minibatch Loss = 1.10139017124e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 700, Minibatch Loss = 3.84550876333e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 800, Minibatch Loss = 0.000175712368218, Training accuracy = 1.0\n",
      "epoch 19, Iter 900, Minibatch Loss = 3.19829050568e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 1000, Minibatch Loss = 9.95951450022e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 1100, Minibatch Loss = 4.1337145376e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 1200, Minibatch Loss = 7.27755559637e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 1300, Minibatch Loss = 0.000170496321516, Training accuracy = 1.0\n",
      "epoch 19, Iter 1400, Minibatch Loss = 2.53635407717e-05, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, Iter 1500, Minibatch Loss = 0.000144827383338, Training accuracy = 1.0\n",
      "epoch 19, Iter 1600, Minibatch Loss = 7.94572042651e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 1700, Minibatch Loss = 4.16628472522e-06, Training accuracy = 1.0\n",
      "epoch 19, Iter 1800, Minibatch Loss = 1.19379747048e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 1900, Minibatch Loss = 0.000357148237526, Training accuracy = 1.0\n",
      "epoch 19, Iter 2000, Minibatch Loss = 5.03573864989e-05, Training accuracy = 1.0\n",
      "epoch 19, Iter 2100, Minibatch Loss = 2.31263106798e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 100, Minibatch Loss = 8.82671974978e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 200, Minibatch Loss = 3.0544011679e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 300, Minibatch Loss = 2.12387494685e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 400, Minibatch Loss = 7.62954878155e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 500, Minibatch Loss = 1.31061215143e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 600, Minibatch Loss = 9.27964902075e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 700, Minibatch Loss = 2.06968252314e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 800, Minibatch Loss = 0.000154089386342, Training accuracy = 1.0\n",
      "epoch 20, Iter 900, Minibatch Loss = 2.58228210441e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 1000, Minibatch Loss = 8.7973112386e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 1100, Minibatch Loss = 3.6953460949e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 1200, Minibatch Loss = 5.71003647565e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 1300, Minibatch Loss = 0.00013233863865, Training accuracy = 1.0\n",
      "epoch 20, Iter 1400, Minibatch Loss = 1.46913243952e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 1500, Minibatch Loss = 0.000143495082739, Training accuracy = 1.0\n",
      "epoch 20, Iter 1600, Minibatch Loss = 5.7263612689e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 1700, Minibatch Loss = 2.59277362602e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 1800, Minibatch Loss = 9.22029630601e-06, Training accuracy = 1.0\n",
      "epoch 20, Iter 1900, Minibatch Loss = 0.000318155973218, Training accuracy = 1.0\n",
      "epoch 20, Iter 2000, Minibatch Loss = 3.81546196877e-05, Training accuracy = 1.0\n",
      "epoch 20, Iter 2100, Minibatch Loss = 1.20400693504e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 100, Minibatch Loss = 7.02693205312e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 200, Minibatch Loss = 1.87421483133e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 300, Minibatch Loss = 1.8027243641e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 400, Minibatch Loss = 4.2225827201e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 500, Minibatch Loss = 8.85094959813e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 600, Minibatch Loss = 7.90906688053e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 700, Minibatch Loss = 7.32502394385e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 800, Minibatch Loss = 0.000123138510389, Training accuracy = 1.0\n",
      "epoch 21, Iter 900, Minibatch Loss = 3.09035931423e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 1000, Minibatch Loss = 9.47659736994e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 1100, Minibatch Loss = 2.95732261293e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 1200, Minibatch Loss = 3.57028511644e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 1300, Minibatch Loss = 0.000133087392896, Training accuracy = 1.0\n",
      "epoch 21, Iter 1400, Minibatch Loss = 7.71251325205e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 1500, Minibatch Loss = 0.000102427366073, Training accuracy = 1.0\n",
      "epoch 21, Iter 1600, Minibatch Loss = 3.46437082044e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 1700, Minibatch Loss = 1.31725505526e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 1800, Minibatch Loss = 6.39526615487e-06, Training accuracy = 1.0\n",
      "epoch 21, Iter 1900, Minibatch Loss = 0.000259128370089, Training accuracy = 1.0\n",
      "epoch 21, Iter 2000, Minibatch Loss = 2.7618745662e-05, Training accuracy = 1.0\n",
      "epoch 21, Iter 2100, Minibatch Loss = 5.42401380699e-07, Training accuracy = 1.0\n",
      "epoch 22, Iter 100, Minibatch Loss = 3.88012267649e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 200, Minibatch Loss = 2.38418010667e-07, Training accuracy = 1.0\n",
      "epoch 22, Iter 300, Minibatch Loss = 5.24494953424e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 400, Minibatch Loss = 0.000102992285974, Training accuracy = 1.0\n",
      "epoch 22, Iter 500, Minibatch Loss = 7.99265217211e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 600, Minibatch Loss = 6.5501676545e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 700, Minibatch Loss = 3.60836347681e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 800, Minibatch Loss = 0.000108689549961, Training accuracy = 1.0\n",
      "epoch 22, Iter 900, Minibatch Loss = 1.69913564605e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 1000, Minibatch Loss = 2.1219050268e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 1100, Minibatch Loss = 2.27877517318e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 1200, Minibatch Loss = 2.69409747489e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 1300, Minibatch Loss = 9.08683578018e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 1400, Minibatch Loss = 5.34039781996e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 1500, Minibatch Loss = 1.84102718777e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 1600, Minibatch Loss = 3.03535489365e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 1700, Minibatch Loss = 1.35897732889e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 1800, Minibatch Loss = 3.8145947201e-06, Training accuracy = 1.0\n",
      "epoch 22, Iter 1900, Minibatch Loss = 0.000267173571046, Training accuracy = 1.0\n",
      "epoch 22, Iter 2000, Minibatch Loss = 1.79400267371e-05, Training accuracy = 1.0\n",
      "epoch 22, Iter 2100, Minibatch Loss = 2.74181189752e-07, Training accuracy = 1.0\n",
      "epoch 23, Iter 100, Minibatch Loss = 2.18744753511e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 200, Minibatch Loss = 1.89566435438e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 300, Minibatch Loss = 5.03635010318e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 400, Minibatch Loss = 2.9380500564e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 500, Minibatch Loss = 5.62654986425e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 600, Minibatch Loss = 7.57521866035e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 700, Minibatch Loss = 1.53994933498e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 800, Minibatch Loss = 9.53146227403e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 900, Minibatch Loss = 1.55189609359e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 1000, Minibatch Loss = 1.10268069875e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1100, Minibatch Loss = 2.08275851037e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 1200, Minibatch Loss = 1.97289705284e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1300, Minibatch Loss = 8.23774171295e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 1400, Minibatch Loss = 5.78140270591e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1500, Minibatch Loss = 4.02323348681e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1600, Minibatch Loss = 1.00429333543e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 1700, Minibatch Loss = 1.54374924932e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1800, Minibatch Loss = 5.65023628951e-06, Training accuracy = 1.0\n",
      "epoch 23, Iter 1900, Minibatch Loss = 0.0002834040788, Training accuracy = 1.0\n",
      "epoch 23, Iter 2000, Minibatch Loss = 1.62117103173e-05, Training accuracy = 1.0\n",
      "epoch 23, Iter 2100, Minibatch Loss = 1.78813849061e-07, Training accuracy = 1.0\n",
      "epoch 24, Iter 100, Minibatch Loss = 1.88347371477e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 200, Minibatch Loss = 1.75921959453e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 300, Minibatch Loss = 9.48220804275e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 400, Minibatch Loss = 4.90916208946e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 500, Minibatch Loss = 1.71765459527e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 600, Minibatch Loss = 4.76815876027e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 700, Minibatch Loss = 2.59391908912e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 800, Minibatch Loss = 8.04710871307e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 900, Minibatch Loss = 1.01381247077e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 1000, Minibatch Loss = 1.34109654937e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 1100, Minibatch Loss = 1.46249094541e-05, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, Iter 1200, Minibatch Loss = 2.11593828681e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 1300, Minibatch Loss = 9.51280162553e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 1400, Minibatch Loss = 1.71063254584e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 1500, Minibatch Loss = 4.85168266096e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 1600, Minibatch Loss = 1.24088928715e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 1700, Minibatch Loss = 7.09292805823e-07, Training accuracy = 1.0\n",
      "epoch 24, Iter 1800, Minibatch Loss = 2.47356069849e-06, Training accuracy = 1.0\n",
      "epoch 24, Iter 1900, Minibatch Loss = 0.000202585477382, Training accuracy = 1.0\n",
      "epoch 24, Iter 2000, Minibatch Loss = 1.22185156215e-05, Training accuracy = 1.0\n",
      "epoch 24, Iter 2100, Minibatch Loss = 1.19209254024e-07, Training accuracy = 1.0\n",
      "epoch 25, Iter 100, Minibatch Loss = 3.28410942529e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 200, Minibatch Loss = 4.55954750578e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 300, Minibatch Loss = 6.40709686195e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 400, Minibatch Loss = 9.66126572166e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 500, Minibatch Loss = 6.36545746602e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 600, Minibatch Loss = 5.35822528036e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 700, Minibatch Loss = 4.64894719698e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 800, Minibatch Loss = 6.22447623755e-05, Training accuracy = 1.0\n",
      "epoch 25, Iter 900, Minibatch Loss = 6.40722191747e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1000, Minibatch Loss = 9.35789898904e-07, Training accuracy = 1.0\n",
      "epoch 25, Iter 1100, Minibatch Loss = 1.06800307549e-05, Training accuracy = 1.0\n",
      "epoch 25, Iter 1200, Minibatch Loss = 2.54505926023e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1300, Minibatch Loss = 6.99151205481e-05, Training accuracy = 1.0\n",
      "epoch 25, Iter 1400, Minibatch Loss = 9.5366988262e-07, Training accuracy = 1.0\n",
      "epoch 25, Iter 1500, Minibatch Loss = 4.42851523985e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1600, Minibatch Loss = 8.63051081978e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1700, Minibatch Loss = 1.86560794191e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1800, Minibatch Loss = 5.0781900427e-06, Training accuracy = 1.0\n",
      "epoch 25, Iter 1900, Minibatch Loss = 0.000136690199724, Training accuracy = 1.0\n",
      "epoch 25, Iter 2000, Minibatch Loss = 1.12170127977e-05, Training accuracy = 1.0\n",
      "epoch 25, Iter 2100, Minibatch Loss = 7.7486021155e-08, Training accuracy = 1.0\n",
      "epoch 26, Iter 100, Minibatch Loss = 1.73446676399e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 200, Minibatch Loss = 1.00542929431e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 300, Minibatch Loss = 1.19803985399e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 400, Minibatch Loss = 5.86950518482e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 500, Minibatch Loss = 2.97420410789e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 600, Minibatch Loss = 5.50122240384e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 700, Minibatch Loss = 1.15560060294e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 800, Minibatch Loss = 4.80366688862e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 900, Minibatch Loss = 1.47818468577e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 1000, Minibatch Loss = 8.70224823757e-07, Training accuracy = 1.0\n",
      "epoch 26, Iter 1100, Minibatch Loss = 1.05191256807e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 1200, Minibatch Loss = 2.9443888252e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 1300, Minibatch Loss = 3.88173830288e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 1400, Minibatch Loss = 4.70875590963e-07, Training accuracy = 1.0\n",
      "epoch 26, Iter 1500, Minibatch Loss = 1.31770193548e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 1600, Minibatch Loss = 1.2313708794e-05, Training accuracy = 1.0\n",
      "epoch 26, Iter 1700, Minibatch Loss = 1.10267978926e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 1800, Minibatch Loss = 1.0490364275e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 1900, Minibatch Loss = 0.000133705252665, Training accuracy = 1.0\n",
      "epoch 26, Iter 2000, Minibatch Loss = 8.92845127964e-06, Training accuracy = 1.0\n",
      "epoch 26, Iter 2100, Minibatch Loss = 3.57627847336e-08, Training accuracy = 1.0\n",
      "epoch 27, Iter 100, Minibatch Loss = 2.44969169216e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 200, Minibatch Loss = 4.05309947382e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 300, Minibatch Loss = 9.01140992937e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 400, Minibatch Loss = 4.23331875936e-05, Training accuracy = 1.0\n",
      "epoch 27, Iter 500, Minibatch Loss = 1.21525627037e-05, Training accuracy = 1.0\n",
      "epoch 27, Iter 600, Minibatch Loss = 5.12597466695e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 700, Minibatch Loss = 3.87428826798e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 800, Minibatch Loss = 2.63778438239e-05, Training accuracy = 1.0\n",
      "epoch 27, Iter 900, Minibatch Loss = 2.32453862736e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1000, Minibatch Loss = 1.01923274087e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1100, Minibatch Loss = 2.03843774216e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1200, Minibatch Loss = 3.31988917424e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1300, Minibatch Loss = 7.04864723957e-05, Training accuracy = 1.0\n",
      "epoch 27, Iter 1400, Minibatch Loss = 3.21864632724e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 1500, Minibatch Loss = 7.56976362482e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 1600, Minibatch Loss = 1.03711795418e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1700, Minibatch Loss = 3.27824693613e-07, Training accuracy = 1.0\n",
      "epoch 27, Iter 1800, Minibatch Loss = 3.98150768888e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 1900, Minibatch Loss = 0.000106697712908, Training accuracy = 1.0\n",
      "epoch 27, Iter 2000, Minibatch Loss = 9.74503745965e-06, Training accuracy = 1.0\n",
      "epoch 27, Iter 2100, Minibatch Loss = 1.78813923668e-08, Training accuracy = 1.0\n",
      "epoch 28, Iter 100, Minibatch Loss = 4.33903051089e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 200, Minibatch Loss = 1.19209273564e-08, Training accuracy = 1.0\n",
      "epoch 28, Iter 300, Minibatch Loss = 6.49686512588e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 400, Minibatch Loss = 1.47143819049e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 500, Minibatch Loss = 9.84612961474e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 600, Minibatch Loss = 1.1503574342e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 700, Minibatch Loss = 2.05534179258e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 800, Minibatch Loss = 2.74324211205e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 900, Minibatch Loss = 9.89429736364e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1000, Minibatch Loss = 4.64915274279e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1100, Minibatch Loss = 4.88138266519e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 1200, Minibatch Loss = 1.43051053669e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1300, Minibatch Loss = 2.31510748563e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 1400, Minibatch Loss = 2.14576559188e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1500, Minibatch Loss = 4.70875590963e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1600, Minibatch Loss = 1.13601399789e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 1700, Minibatch Loss = 4.76835566587e-07, Training accuracy = 1.0\n",
      "epoch 28, Iter 1800, Minibatch Loss = 1.88348860775e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 1900, Minibatch Loss = 4.83279654873e-05, Training accuracy = 1.0\n",
      "epoch 28, Iter 2000, Minibatch Loss = 8.35036371427e-06, Training accuracy = 1.0\n",
      "epoch 28, Iter 2100, Minibatch Loss = 1.19209282445e-08, Training accuracy = 1.0\n",
      "epoch 29, Iter 100, Minibatch Loss = 2.82518021777e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 200, Minibatch Loss = 7.27171368453e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 300, Minibatch Loss = 1.72853305003e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 400, Minibatch Loss = 1.15977500172e-05, Training accuracy = 1.0\n",
      "epoch 29, Iter 500, Minibatch Loss = 1.04779537651e-05, Training accuracy = 1.0\n",
      "epoch 29, Iter 600, Minibatch Loss = 6.49686967336e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 700, Minibatch Loss = 5.91839079789e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 800, Minibatch Loss = 1.98345915123e-05, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, Iter 900, Minibatch Loss = 2.25897247219e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 1000, Minibatch Loss = 3.63587332686e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 1100, Minibatch Loss = 2.30664682022e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 1200, Minibatch Loss = 2.23512643061e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 1300, Minibatch Loss = 3.63456420018e-05, Training accuracy = 1.0\n",
      "epoch 29, Iter 1400, Minibatch Loss = 2.56299756529e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 1500, Minibatch Loss = 2.80141250641e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 1600, Minibatch Loss = 6.246414614e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 1700, Minibatch Loss = 3.27824722035e-07, Training accuracy = 1.0\n",
      "epoch 29, Iter 1800, Minibatch Loss = 3.33182515533e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 1900, Minibatch Loss = 2.1107516659e-05, Training accuracy = 1.0\n",
      "epoch 29, Iter 2000, Minibatch Loss = 6.22854804533e-06, Training accuracy = 1.0\n",
      "epoch 29, Iter 2100, Minibatch Loss = 2.38418547127e-08, Training accuracy = 1.0\n",
      "epoch 30, Iter 100, Minibatch Loss = 2.312606739e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 200, Minibatch Loss = 4.80390372104e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 300, Minibatch Loss = 1.60932302151e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 400, Minibatch Loss = 1.97508197743e-05, Training accuracy = 1.0\n",
      "epoch 30, Iter 500, Minibatch Loss = 1.04720602394e-05, Training accuracy = 1.0\n",
      "epoch 30, Iter 600, Minibatch Loss = 7.15250962458e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 700, Minibatch Loss = 5.25089353687e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 800, Minibatch Loss = 2.49828190135e-05, Training accuracy = 1.0\n",
      "epoch 30, Iter 900, Minibatch Loss = 1.90734652961e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 1000, Minibatch Loss = 7.74860140496e-08, Training accuracy = 1.0\n",
      "epoch 30, Iter 1100, Minibatch Loss = 3.1589468108e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 1200, Minibatch Loss = 2.62260073214e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 1300, Minibatch Loss = 3.54224139301e-05, Training accuracy = 1.0\n",
      "epoch 30, Iter 1400, Minibatch Loss = 1.25169634657e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 1500, Minibatch Loss = 1.13248759703e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 1600, Minibatch Loss = 8.9406665893e-07, Training accuracy = 1.0\n",
      "epoch 30, Iter 1700, Minibatch Loss = 7.15255268346e-08, Training accuracy = 1.0\n",
      "epoch 30, Iter 1800, Minibatch Loss = 2.82521295958e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 1900, Minibatch Loss = 1.71215033333e-05, Training accuracy = 1.0\n",
      "epoch 30, Iter 2000, Minibatch Loss = 5.69214080315e-06, Training accuracy = 1.0\n",
      "epoch 30, Iter 2100, Minibatch Loss = 5.96046412227e-09, Training accuracy = 1.0\n",
      "epoch 31, Iter 100, Minibatch Loss = 2.15168120121e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 200, Minibatch Loss = 1.19209273564e-08, Training accuracy = 1.0\n",
      "epoch 31, Iter 300, Minibatch Loss = 2.68220162525e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 400, Minibatch Loss = 2.80733684122e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 500, Minibatch Loss = 6.07952642895e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 600, Minibatch Loss = 5.48360389985e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 700, Minibatch Loss = 3.88011176256e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 800, Minibatch Loss = 1.53886849148e-05, Training accuracy = 1.0\n",
      "epoch 31, Iter 900, Minibatch Loss = 2.92062082963e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 1000, Minibatch Loss = 2.74180962379e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 1100, Minibatch Loss = 2.15168120121e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 1200, Minibatch Loss = 8.70220276283e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 1300, Minibatch Loss = 1.41719774547e-05, Training accuracy = 1.0\n",
      "epoch 31, Iter 1400, Minibatch Loss = 1.01327827906e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 1500, Minibatch Loss = 9.53673762183e-08, Training accuracy = 1.0\n",
      "epoch 31, Iter 1600, Minibatch Loss = 2.78946276921e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 1700, Minibatch Loss = 1.01327827906e-07, Training accuracy = 1.0\n",
      "epoch 31, Iter 1800, Minibatch Loss = 2.79541632153e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 1900, Minibatch Loss = 2.49562053796e-05, Training accuracy = 1.0\n",
      "epoch 31, Iter 2000, Minibatch Loss = 2.57489705291e-06, Training accuracy = 1.0\n",
      "epoch 31, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 32, Iter 100, Minibatch Loss = 2.37816880144e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 200, Minibatch Loss = 1.78813905904e-08, Training accuracy = 1.0\n",
      "epoch 32, Iter 300, Minibatch Loss = 3.57627776282e-08, Training accuracy = 1.0\n",
      "epoch 32, Iter 400, Minibatch Loss = 6.06748699283e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 500, Minibatch Loss = 3.96360201194e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 600, Minibatch Loss = 4.29152493098e-07, Training accuracy = 1.0\n",
      "epoch 32, Iter 700, Minibatch Loss = 1.19803894449e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 800, Minibatch Loss = 1.47630171341e-05, Training accuracy = 1.0\n",
      "epoch 32, Iter 900, Minibatch Loss = 2.26497292033e-07, Training accuracy = 1.0\n",
      "epoch 32, Iter 1000, Minibatch Loss = 2.14576331814e-07, Training accuracy = 1.0\n",
      "epoch 32, Iter 1100, Minibatch Loss = 2.50333232543e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 1200, Minibatch Loss = 3.23046742778e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 1300, Minibatch Loss = 5.77535729462e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 1400, Minibatch Loss = 8.94069245305e-08, Training accuracy = 1.0\n",
      "epoch 32, Iter 1500, Minibatch Loss = 5.96046270118e-08, Training accuracy = 1.0\n",
      "epoch 32, Iter 1600, Minibatch Loss = 3.49874130734e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 1700, Minibatch Loss = 4.76837058727e-08, Training accuracy = 1.0\n",
      "epoch 32, Iter 1800, Minibatch Loss = 2.01461671168e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 1900, Minibatch Loss = 2.59272746916e-05, Training accuracy = 1.0\n",
      "epoch 32, Iter 2000, Minibatch Loss = 3.6477492813e-06, Training accuracy = 1.0\n",
      "epoch 32, Iter 2100, Minibatch Loss = 1.78813923668e-08, Training accuracy = 1.0\n",
      "epoch 33, Iter 100, Minibatch Loss = 1.64506104738e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 200, Minibatch Loss = 1.43050939982e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 300, Minibatch Loss = 2.98023170586e-08, Training accuracy = 1.0\n",
      "epoch 33, Iter 400, Minibatch Loss = 3.33776119987e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 500, Minibatch Loss = 3.48681282958e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 600, Minibatch Loss = 3.33784953455e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 700, Minibatch Loss = 2.71789804174e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 800, Minibatch Loss = 6.52651306154e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 900, Minibatch Loss = 8.94069245305e-08, Training accuracy = 1.0\n",
      "epoch 33, Iter 1000, Minibatch Loss = 7.74859856278e-08, Training accuracy = 1.0\n",
      "epoch 33, Iter 1100, Minibatch Loss = 2.44969078267e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 1200, Minibatch Loss = 9.29824182094e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 1300, Minibatch Loss = 6.77063144394e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 1400, Minibatch Loss = 1.19209161653e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 1500, Minibatch Loss = 6.85448753757e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 1600, Minibatch Loss = 1.18612729239e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 1700, Minibatch Loss = 1.37090552244e-07, Training accuracy = 1.0\n",
      "epoch 33, Iter 1800, Minibatch Loss = 1.59143053224e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 1900, Minibatch Loss = 1.57212343765e-05, Training accuracy = 1.0\n",
      "epoch 33, Iter 2000, Minibatch Loss = 4.05304399465e-06, Training accuracy = 1.0\n",
      "epoch 33, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 34, Iter 100, Minibatch Loss = 2.39008909375e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 200, Minibatch Loss = 5.00676492265e-07, Training accuracy = 1.0\n",
      "epoch 34, Iter 300, Minibatch Loss = 5.96046412227e-09, Training accuracy = 1.0\n",
      "epoch 34, Iter 400, Minibatch Loss = 1.10497703645e-05, Training accuracy = 1.0\n",
      "epoch 34, Iter 500, Minibatch Loss = 2.52719883065e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 600, Minibatch Loss = 8.94069174251e-08, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, Iter 700, Minibatch Loss = 1.92519291886e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 800, Minibatch Loss = 4.63715377919e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 900, Minibatch Loss = 3.03983000549e-07, Training accuracy = 1.0\n",
      "epoch 34, Iter 1000, Minibatch Loss = 2.62259874262e-07, Training accuracy = 1.0\n",
      "epoch 34, Iter 1100, Minibatch Loss = 1.89539173334e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 1200, Minibatch Loss = 9.71546228357e-07, Training accuracy = 1.0\n",
      "epoch 34, Iter 1300, Minibatch Loss = 1.76637004188e-05, Training accuracy = 1.0\n",
      "epoch 34, Iter 1400, Minibatch Loss = 6.55650893577e-08, Training accuracy = 1.0\n",
      "epoch 34, Iter 1500, Minibatch Loss = 2.38418547127e-08, Training accuracy = 1.0\n",
      "epoch 34, Iter 1600, Minibatch Loss = 2.92062452445e-07, Training accuracy = 1.0\n",
      "epoch 34, Iter 1700, Minibatch Loss = 5.96046412227e-09, Training accuracy = 1.0\n",
      "epoch 34, Iter 1800, Minibatch Loss = 1.71063823018e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 1900, Minibatch Loss = 8.92798016139e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 2000, Minibatch Loss = 3.26034091813e-06, Training accuracy = 1.0\n",
      "epoch 34, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 35, Iter 100, Minibatch Loss = 9.05982403765e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 200, Minibatch Loss = 3.15903605497e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 300, Minibatch Loss = 1.19209282445e-08, Training accuracy = 1.0\n",
      "epoch 35, Iter 400, Minibatch Loss = 2.39010296355e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 500, Minibatch Loss = 2.0265256353e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 600, Minibatch Loss = 1.25169620446e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 700, Minibatch Loss = 1.44837190419e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 800, Minibatch Loss = 7.43235887057e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 900, Minibatch Loss = 2.02655570547e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 1000, Minibatch Loss = 7.56974088745e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 1100, Minibatch Loss = 1.72254453901e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 1200, Minibatch Loss = 8.94068961088e-08, Training accuracy = 1.0\n",
      "epoch 35, Iter 1300, Minibatch Loss = 4.6608665798e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 1400, Minibatch Loss = 1.01327792379e-07, Training accuracy = 1.0\n",
      "epoch 35, Iter 1500, Minibatch Loss = 1.5437365164e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 1600, Minibatch Loss = 2.57488272837e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 1700, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 35, Iter 1800, Minibatch Loss = 1.6808349983e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 1900, Minibatch Loss = 6.2223380155e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 2000, Minibatch Loss = 2.87887769446e-06, Training accuracy = 1.0\n",
      "epoch 35, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 36, Iter 100, Minibatch Loss = 1.4006894844e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 200, Minibatch Loss = 1.59737896865e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 300, Minibatch Loss = 5.96046412227e-09, Training accuracy = 1.0\n",
      "epoch 36, Iter 400, Minibatch Loss = 9.53667949943e-07, Training accuracy = 1.0\n",
      "epoch 36, Iter 500, Minibatch Loss = 1.53182895701e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 600, Minibatch Loss = 1.25169663079e-07, Training accuracy = 1.0\n",
      "epoch 36, Iter 700, Minibatch Loss = 1.38280870488e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 800, Minibatch Loss = 6.4071818997e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 900, Minibatch Loss = 6.07964523169e-07, Training accuracy = 1.0\n",
      "epoch 36, Iter 1000, Minibatch Loss = 5.36441575605e-08, Training accuracy = 1.0\n",
      "epoch 36, Iter 1100, Minibatch Loss = 1.8477097683e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 1200, Minibatch Loss = 1.48413369061e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 1300, Minibatch Loss = 4.88755745209e-07, Training accuracy = 1.0\n",
      "epoch 36, Iter 1400, Minibatch Loss = 5.36441504551e-08, Training accuracy = 1.0\n",
      "epoch 36, Iter 1500, Minibatch Loss = 9.22594790609e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 1600, Minibatch Loss = 2.27091186389e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 1700, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 36, Iter 1800, Minibatch Loss = 8.34461559407e-07, Training accuracy = 1.0\n",
      "epoch 36, Iter 1900, Minibatch Loss = 6.35941114524e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 2000, Minibatch Loss = 1.46030708947e-06, Training accuracy = 1.0\n",
      "epoch 36, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 37, Iter 100, Minibatch Loss = 1.19803894449e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 200, Minibatch Loss = 1.3351261714e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 300, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 37, Iter 400, Minibatch Loss = 1.10267569653e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 500, Minibatch Loss = 1.93712344299e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 600, Minibatch Loss = 1.96695083332e-07, Training accuracy = 1.0\n",
      "epoch 37, Iter 700, Minibatch Loss = 1.20399931802e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 800, Minibatch Loss = 4.42853979621e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 900, Minibatch Loss = 7.15255481509e-08, Training accuracy = 1.0\n",
      "epoch 37, Iter 1000, Minibatch Loss = 2.01459670279e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 1100, Minibatch Loss = 1.59141870881e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 1200, Minibatch Loss = 1.29340401145e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 1300, Minibatch Loss = 1.46625302477e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 1400, Minibatch Loss = 1.78813621687e-07, Training accuracy = 1.0\n",
      "epoch 37, Iter 1500, Minibatch Loss = 1.78813905904e-08, Training accuracy = 1.0\n",
      "epoch 37, Iter 1600, Minibatch Loss = 7.39095753488e-07, Training accuracy = 1.0\n",
      "epoch 37, Iter 1700, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 37, Iter 1800, Minibatch Loss = 4.23192062726e-07, Training accuracy = 1.0\n",
      "epoch 37, Iter 1900, Minibatch Loss = 2.76557921097e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 2000, Minibatch Loss = 3.29608747052e-06, Training accuracy = 1.0\n",
      "epoch 37, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 38, Iter 100, Minibatch Loss = 8.52339155699e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 200, Minibatch Loss = 1.3351261714e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 300, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 38, Iter 400, Minibatch Loss = 1.19209273564e-08, Training accuracy = 1.0\n",
      "epoch 38, Iter 500, Minibatch Loss = 1.91924732462e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 600, Minibatch Loss = 1.66892874631e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 700, Minibatch Loss = 1.0728720099e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 800, Minibatch Loss = 2.17555179916e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 900, Minibatch Loss = 1.07288272488e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 1000, Minibatch Loss = 1.6689286042e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 1100, Minibatch Loss = 8.64259902755e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 1200, Minibatch Loss = 1.01922910289e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 1300, Minibatch Loss = 1.16823741791e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 1400, Minibatch Loss = 6.5565060936e-08, Training accuracy = 1.0\n",
      "epoch 38, Iter 1500, Minibatch Loss = 5.37604955753e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 1600, Minibatch Loss = 9.53668575221e-07, Training accuracy = 1.0\n",
      "epoch 38, Iter 1700, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 38, Iter 1800, Minibatch Loss = 1.35897414566e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 1900, Minibatch Loss = 5.84091412748e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 2000, Minibatch Loss = 2.78350717053e-06, Training accuracy = 1.0\n",
      "epoch 38, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 39, Iter 100, Minibatch Loss = 1.84774052059e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 200, Minibatch Loss = 1.04307036963e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 300, Minibatch Loss = 5.96046412227e-09, Training accuracy = 1.0\n",
      "epoch 39, Iter 400, Minibatch Loss = 4.76836916619e-08, Training accuracy = 1.0\n",
      "epoch 39, Iter 500, Minibatch Loss = 6.13926204096e-07, Training accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, Iter 600, Minibatch Loss = 5.12598148816e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 700, Minibatch Loss = 9.35784214562e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 800, Minibatch Loss = 1.40666145398e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 900, Minibatch Loss = 8.94068961088e-08, Training accuracy = 1.0\n",
      "epoch 39, Iter 1000, Minibatch Loss = 1.78813763796e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 1100, Minibatch Loss = 1.71062401932e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 1200, Minibatch Loss = 5.72201315663e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 1300, Minibatch Loss = 1.96694983856e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 1400, Minibatch Loss = 2.38418529364e-08, Training accuracy = 1.0\n",
      "epoch 39, Iter 1500, Minibatch Loss = 5.78727576794e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 1600, Minibatch Loss = 1.22188703244e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 1700, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "epoch 39, Iter 1800, Minibatch Loss = 4.6491496164e-07, Training accuracy = 1.0\n",
      "epoch 39, Iter 1900, Minibatch Loss = 3.02782427752e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 2000, Minibatch Loss = 2.71197495749e-06, Training accuracy = 1.0\n",
      "epoch 39, Iter 2100, Minibatch Loss = 0.0, Training accuracy = 1.0\n",
      "Optimization Completed\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        step = 1\n",
    "        while step*batch_size <= train_data.shape[0]:\n",
    "            xs, ys = train_data[(step-1)*batch_size:step*batch_size, :], train_label[(step-1)*batch_size:step*batch_size, :]\n",
    "            sess.run(optimizer, feed_dict={X:xs, y:ys})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss, acc = sess.run([cost,accuracy], feed_dict={X:xs, y:ys})\n",
    "                print(\"epoch {0}, Iter {1}, Minibatch Loss = {2}, Training accuracy = {3}\".format(str(e), str(step),loss,acc))\n",
    "                \n",
    "            step += 1\n",
    "    print(\"Optimization Completed\")\n",
    "    test_labels = []\n",
    "    for i in range(1000):\n",
    "        xs, ys = test_data[i*28:(i+1)*28, :], test_data[i*28:(i+1)*28, 0:10]\n",
    "        pred_ = sess.run(label, feed_dict={X:xs, y:ys})\n",
    "        test_labels.extend(list(pred_))\n",
    "        \n",
    "f1 = open('label','wb')\n",
    "pickle.dump(test_labels, f1)\n",
    "f1.close()\n",
    "\n",
    "df = pd.DataFrame({'Label' : test_labels})\n",
    "df1 = pd.concat([pd.Series(range(1,28001), name='ImageId'), df[['Label']]], axis=1)\n",
    "df1.to_csv('ConvPool_X2.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
